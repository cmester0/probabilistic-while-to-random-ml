% -------------------------------------------------------------
% Document setup 
% -------------------------------------------------------------
\documentclass[11pt, leqno, titlepage]{article}
\usepackage{graphicx}
%\usepackage[left=30mm,right=30mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
% -------------------------------------------------------------
% Notation aids 
% -------------------------------------------------------------
\usepackage{amsmath} % American Mathematical Society math-notations
\usepackage{amssymb} % American Mathematical Society math-symbols
\usepackage{amsthm}  % For good looking definitions and theorems
\usepackage{stmaryrd} % For interpretation bracket (and maybe other stuff)
\usepackage{listings}

% -------------------------------------------------------------
% For convenient development
% -------------------------------------------------------------
\usepackage{todonotes}

\lstdefinelanguage{Coq}{ 
%
% Anything betweeen $ becomes LaTeX math mode
mathescape=true,
%
% Comments may or not include Latex commands
texcl=false, 
%
% Vernacular commands
morekeywords=[1]{Section, Module, End, Require, Import, Export,
  Variable, Variables, Parameter, Parameters, Axiom, Hypothesis,
  Hypotheses, Notation, Local, Tactic, Reserved, Scope, Open, Close,
  Bind, Delimit, Definition, Let, Ltac, Fixpoint, CoFixpoint, Add,
  Morphism, Relation, Implicit, Arguments, Unset, Contextual,
  Strict, Prenex, Implicits, Inductive, CoInductive, Record,
  Structure, Canonical, Coercion, Context, Class, Global, Instance,
  Program, Infix, Theorem, Lemma, Corollary, Proposition, Fact,
  Remark, Example, Proof, Goal, Save, Qed, Defined, Hint, Resolve,
  Rewrite, View, Search, Show, Print, Printing, All, Eval, Check,
  Projections, inside, outside, Def},
%
% Gallina
morekeywords=[2]{forall, exists, exists2, fun, fix, cofix, struct,
  match, with, end, as, in, return, let, if, is, then, else, for, of,
  nosimpl, when},
%
% Sorts
morekeywords=[3]{Type, Prop, Set, true, false, option},
%
% Various tactics, some are std Coq subsumed by ssr, for the manual purpose
morekeywords=[4]{pose, set, move, case, elim, apply, clear, hnf,
  intro, intros, generalize, rename, pattern, after, destruct,
  induction, using, refine, inversion, injection, rewrite, congr,
  unlock, compute, ring, field, fourier, replace, fold, unfold,
  change, cutrewrite, simpl, have, suff, wlog, suffices, without,
  loss, nat_norm, assert, cut, trivial, revert, bool_congr, nat_congr,
  symmetry, transitivity, auto, split, left, right, autorewrite},
%
% Terminators
morekeywords=[5]{by, done, exact, reflexivity, tauto, romega, omega,
  assumption, solve, contradiction, discriminate},
%
% Control
morekeywords=[6]{do, last, first, try, idtac, repeat},
% % Custom
morekeywords=[7]{Rml, sRml},
morekeywords=[8]{Var, Const, Let_stm, Fun_stm, If_stm, App_stm, Let_rec},
morekeywords=[9]{sVar, sConst, sFun, sIf, sApp, sFix},
% Comments delimiters, we do turn this off for the manual
morecomment=[s]{(*}{*)},
%
% Spaces are not displayed as a special character
showstringspaces=false,
%
% String delimiters
morestring=[b]",
morestring=[d],
%
% Size of tabulations
tabsize=3,
%
% Enables ASCII chars 128 to 255
extendedchars=false,
%
% Case sensitivity
sensitive=true,
%
% Automatic breaking of long lines
breaklines=false,
%
% Default style fors listings
basicstyle=\small,
%
% Position of captions is bottom
captionpos=b,
%
% flexible columns
columns=[l]flexible,
%
% Style for (listings') identifiers
identifierstyle={\ttfamily\color{black}},
% Style for declaration keywords
keywordstyle=[1]{\ttfamily\color{violet}},
% Style for gallina keywords
keywordstyle=[2]{\ttfamily\color{green}},
% Style for sorts keywords
keywordstyle=[3]{\ttfamily\color{blue}},
% Style for tactics keywords
keywordstyle=[4]{\ttfamily\color{blue}},
% Style for terminators keywords
keywordstyle=[5]{\ttfamily\color{red}},
%Style for iterators
%keywordstyle=[6]{\ttfamily\color{dkpink}},
keywordstyle=[7]{\ttfamily\color{orange}},
keywordstyle=[8]{\ttfamily\color{red}},
keywordstyle=[9]{\ttfamily\color{magenta}},
% Style for strings
stringstyle=\ttfamily,
% Style for comments
commentstyle={\ttfamily\color{purple}},
%
%moredelim=**[is][\ttfamily\color{red}]{/&}{&/},
literate=
    {\\forall}{{\color{dkgreen}{$\forall\;$}}}1
    {\\exists}{{$\exists\;$}}1
    {<-}{{$\leftarrow\;$}}1
    {=>}{{$\Rightarrow\;$}}1
    {==}{{\code{==}\;}}1
    {==>}{{\code{==>}\;}}1
%    {:>}{{\code{:>}\;}}1
    {->}{{$\rightarrow\;$}}1
    {<->}{{$\leftrightarrow\;$}}1
    {<==}{{$\leq\;$}}1
    {\#}{{$^\star$}}1 
    {\\o}{{$\circ\;$}}1 
    {\@}{{$\cdot$}}1 
    {\/\\}{{$\wedge\;$}}1
    {\\\/}{{$\vee\;$}}1
    {++}{{\code{++}}}1
    {~}{{\ }}1
    {nat}{{$\mathbb{N}$}}1
    {forall}{{$\forall$}}1
    {\@\@}{{$@$}}1
    {\\mapsto}{{$\mapsto\;$}}1
    {\\hline}{{\rule{\linewidth}{0.5pt}}}1
%
}[keywords,comments,strings]

\lstnewenvironment{coq}{\lstset{language=Coq}}{}

% pour inliner dans le texte
\def\coqe{\lstinline[language=Coq, basicstyle=\small]}
% pour inliner dans les tableaux / displaymath...
\def\coqes{\lstinline[language=Coq, basicstyle=\scriptsize]}

% \lstdefinelanguage{rml}{
% }

% \lstdefinelanguage{pwhile}{
% }
\lstdefinelanguage{pwhile}{
}
% -------------------------------------------------------------
% Prettyfying
% -------------------------------------------------------------
\usepackage[hidelinks]{hyperref}

\usepackage{xcolor}
% -------------------------------------------------------------

\author{Lasse Letager Hansen %201508114
  \\ Kira Kutscher %201509720
}
\date{\today}
\title{Technical report}

\newcommand{\set}[1]{\{#1\}}

\newcommand{\Rml}{\textcolor{orange}{\mathtt{Rml}}}
\newcommand{\sRml}{\textcolor{orange}{\mathtt{sRml}}}
\newcommand{\Type}{\textcolor{blue}{\mathtt{Type}}}
\newcommand{\wellformed}{\texttt{well\_formed}}
\newcommand{\valid}{\texttt{rml\_valid\_type}}
\newcommand{\bind}{>\!\!>\!\!=}

\theoremstyle{definition}
\newtheorem{thm}{Theorem}
\newtheorem{defn}[thm]{Definition}

\begin{document}

% -------------------------------------------------------------

\newcommand\rml{$\mathcal{R}$\texttt{ml} } % for a pretty version of "Rml"
\newcommand\M{\texttt{M}} % for the M representing monads

% -------------------------------------------------------------

\maketitle

\tableofcontents
\newpage

% ------------------------------------------------------------- 

\section{Introduction (Finished 12.06.)}
% Goal: 1-2 pages
% I've written an introduction already, but I don't know if it still fits. We should
% probably write the rest of the report first before adding this section

% here we should write something about the motivation of the project and give an
% overview of what Coq/formal verification is, some very basic things about
% cryptography, and how they relate.

\todo[inline, color=green!40]{Probabilistic algorithms are widely used, but far less
  widely proved correct. We explore some probabilistic languages and how to embed
  them in the widely known and trusted proof assistant Coq. Having an interpretation
  of such a language in Coq makes it possible to prove facts about the algorithms in
  Coq's proof logic.

  We explore both a functional design, as presented in [...], %\cite{RML paper}
  and an imperative one, as in [...]. %\cite{EasyCrypt stuff}
}


\section{Theory and existing frameworks (DRAFT READY, minor additions needed)} 
% Goal: 6-12 pages

\todo[inline, color=green!40]{As mentioned before we focused our work on developing a
  framework for proofs of randomised algorithms in the proof assistant Coq. Coq is
  known to be a reliable tool and proofs formalised with it are widely trusted. Coq
  is, however, also known to be notoriously difficult to code things in due to a
  strict type system that requires determinism and certain termination of all
  programs written in it. Obviously these two are not the optimal conditions for the
  encoding of randomised algorithms that may not terminate.

  This means that we need a way to encode an interpretation general recursion (or
  iteration) as well as randomness in such a way that we can still reason about our
  programs in the proof system of Coq without having to run them.

  We will in this section present a monadic interpretation into probability
  distribution over the outcome of a randomised program as well as a way of
  interpreting general recursion.}

\todo[inline, color=green!40]{In this section we will have a look at how to use
  complete partial orders to interpret general recursion (Section \ref{sec:cpos}), and
  how we can represent the result of a probabilistic computation using a monadic
  interpretation of probability measures (Section \ref{sec:prob-interp}. Afterwards we
  will move on to presenting two different developments that have worked with
  probabilistic languages in Coq: the functional \rml (Section \ref{sec:rml}) and the
  imperative \texttt{pwhile} (Section \ref{sec:pwhile}).}

\subsection{Complete partial orders}\label{sec:cpos}
% Describe cpos, omega-cpos, and dcpos
% partial order: a set with an ordering relation, but not every two elements have to
% be comparable

A partially ordered set (poset) is a set with an associated binary ordering relation
$\leq$ which is both reflexive and transitive. The order is partial when the ordering
relation is not defined on every pair of elements in the set.

There exist a number of different completeness properties that a poset can have.
We will here have a look at $\omega$-complete partial orders, which we will use in
order to interpret general recursion and probabilistic programs. 

\begin{defn}
  \textit{$\omega$-complete partial order ($\omega$-cpo)}\\
  An $\omega$-cpo is a partially ordered set that, additionally, has a distinct least
  element and where there exist least upper bounds on all monotonic sequences. 
\end{defn}


\subsubsection{Recursive definitions as fixed point iterations}
% Describe the fixpoint interpretation of recursive/iterative definitions

Before using $\omega$-cpos to interpret recursion, let us first have a look at some
interesting things that our definition entails.

A monotonic sequence on an $\omega$-cpo $X$ can be viewed as a monotonic function
$f~:~\mathbb{N} \xrightarrow{m} X$ where $f(n)$ is the $n$th element of the sequence (or the
least upper bound of the sequence, if $n$ is larger than the length of the
sequence).\\
\\
% Standard definition of fixed points
There is a standard way of defining fixed point iterations on an $\omega$-cpo: % \cite{alea}

Consider an operator $F~:~X \xrightarrow{m} X$ on some $\omega$-cpo $X$; with this we
define the monotonic sequence $F_i \mapsto \underbrace{ F(F(\dots F}_{i \text{
    times}} (0_X) \dots))$ of repeated application of $F$ to the least element of $X$.
By our choice of $F$ and the definition of $\omega$-cpos, it is clear that there has
to exist a least upper bound on $F_i$. This least upper bound is the fixed point of
$F$ and it will hold that $\texttt{fix } F = F(\texttt{fix }F)$ if $F$ is
continuous. 
% @Bas: Where do we need non-continuous functions?

% How it extends to function spaces
For an $\omega$-cpo with underlying set $B$ we can also define an $\omega$-cpo on
functions from any set $A$ whose co-domain is $B$.

To reiterate the definition, let us think of what we need for an $\omega$-cpo. We
need an ordering relation, a least element, and a least upper bound operation. Those
can be defined as follows:
\begin{align*}
  f\leq_{A \to B} g \Leftrightarrow \forall x: f(x) \leq_B g(x) & ~~~\textit{(pointwise order)}\\
  0_{A\to B} := f(x) = 0_B & ~~~\textit{(least element)}\\
  \texttt{lub}_{A\to B} f_n := g(x) = \texttt{lub}_B(f_n(x)) & ~~~\textit{(least upper
                                                               bound operation)}
\end{align*}


% How this can be used to interpret recursion
The result of an interpretation of programs in the language of discourse will be in
an $\omega$-cpo, so according to the above discussion functions will have an
$\omega$-cpo structure as well. Together with the above definition of fixed points we
can use this structure to interpret general recursive definitions. 

We define a functional, $F$, taking as input a function and ``adding a step to it''.
Let us look at the example of the factorial function $f(n) = n!$. %\cite{haskell}
The recursive definition is well known:
$$fac(n) := \texttt{ if } n = 0 \texttt{ then }1\texttt{ else } n\cdot fac(n-1)$$

For the interpretation of this definition, we want to define $F~:~(\mathbb{N} \to
\mathbb{N}) \to (\mathbb{N} \to \mathbb{N})$ in such a way that its fixed point is
the same as the above recursive definition. We choose
$$F(F_i(n)):=\texttt{ if }n=0\texttt{ then }1\texttt{ else }n\cdot F_i(n-1)$$
Where $F_0(n)$ is $0_{\mathbb{N} \to \mathbb{N}}$ (the function that takes a natural
number and returns 0), by the above definition of the least element in the
$\omega$-cpo defined on a function space. By repeated application of $F$ the function
will slowly approach the real factorial function, which is the fixed point of $F$.
The beginning of the iteration will be

\begin{align*}
  F_1(n) = F(F_0(n)) & = \begin{cases}
                           1~~~\text{if }n\text{ is 0}\\
                           0~~~\text{otherwise}
                         \end{cases}
  \\
  F_2(n) = F(F(F_0(n))) & = \begin{cases}
                             1~~~\text{if }n\text{ is 0}\\
                             1~~~\text{if }n\text{ is 1}\\
                             0~~~\text{otherwise}
                           \end{cases}
  \\
  F_3(n) = F(F(F(F_0(n)))) & = \begin{cases}
                                1~~~\text{if }n\text{ is 0}\\
                                1~~~\text{if }n\text{ is 1}\\
                                2~~~\text{if }n\text{ is 2}\\
                                0~~~\text{otherwise}
                              \end{cases}
\end{align*}

In this case it is easy to see that $F_0 \leq F_1 \leq F_2 \leq F_3 \leq \dots$. In
the general case this follows from the fact that $F$ has to be monotone and $F_0$ is
always the least element of the function space $F$ operates on. 


\subsection{Interpreting probabilistic definitions}\label{sec:prob-interp}
In order to interpret probabilistic definitions, we need a way of expressing
the distribution of possible results. For this we will use probability measures as
described in [...].% \cite{rml-paper}

\subsubsection{The concept of measures}
In layman's terms, we can describe a measure on a set $A$ as exactly that: a way of
measuring subsets of $A$. More precisely, a measure on $A$ assigns a non-negative
real number to every ``suitable'' subset of $A$, where ``suitable'' means fulfilling
certain arbitrary conditions. We will henceforth write $\mu (X)$ to signify the value
of $X \subseteq A$ under the measure $\mu$. 

In order for a function to be a measure, there are three properties it has to have:
It must take only non-negative values, $\mu (\varnothing) = 0$, and it has to be
countably additive. Being countably additive means that for every set of pairwise
disjoint objects, the value of this set is equal to the sum of the values of each
object:

\begin{equation*}
  \mu (X) = \mu(\bigcup_{x\in X} x) = \Sigma_{x\in X} \mu (x)
\end{equation*}

An example might be to choose $A$ to be a set of 3-dimensional objects and a possible
measure would be the total volume of objects in a subset. 

\todo{Is this understood correctly?} We can understand a measure on $A$ as integral
over functions from $A$ to $\mathbb{R}^+$. From this perspective, the above example
would consist of the function that given an object in $A$ returns its volume. The
integral over this function would be the volume of all objects in $A$. Now the
challenge is to measure only a subset of $A$. We can do this by introducing the
characteristic function of a subset $X$:%\cite{wikipedia on measures}

$$\mathbb{I}_X(x)=
\begin{cases}
  1~~\text{if }x\in X\\
  0~~\text{otherwise}
\end{cases}$$

By multiplying the characteristic function for $X$ with the volume function on
objects in $A$, we get a new function, $f$, such that $\int f~d\mu = \mu(X)$. With
this in place, we will allow ourselves to be sloppy in our notation and write
$\mu(f)$ instead of $\int f~d\mu$.

It is easy to see that the integral perspective still satisfies all the requirements
that a function has to fulfil in order to be a measure, and the reader is invited to
check this for herself.\\
\\
Now why all this talk about measures? Wasn't it probabilistic programs we were
talking about?

Well, yes. The cool thing is, that being able to measure function whose co-domain is
the real numbers in the unit interval, $\tau\to[0,1]$, gives us a way of representing
probability distributions. A measure on type $\tau$ can be expressed with the type
$(\tau\to[0,1])\to[0,1]$. An interpretation of a probabilistic term whose type is
$\tau$ can now be understood as a measure on type $\tau$, or equivalently as a
transformation of a probability distribution.

Something of type $\tau\to[0,1]$ can be understood as the function that returns the
probability of its input happening, or in other words, we can understand it as a
probability density function. We can view our programs as a transformation of a
distribution: If we input an initial distribution (this might also just be the
characteristic function of a single value), we will as output receive the integral
over the transformed distribution; with other words, we will receive the probability
of the result of an actual pseudorandomised run of our program producing a result
within the input distribution.
\todo[inline]{Or something like that... I am very unsure about what exactly we get
  when we input an initial distribution... help?\\
  It seems we get the integral over the joint distribution (given that both
  distributions are independent, which we will have to assume).}
\todo[inline]{Geistesblitz! The input is a function that expresses the probability of
  something being memeber of some set. The characteristic function of a set is
  non-probabilistic and hence the result of inputting this will give the exact
  probability of our result being part of that set. If we, for example, have a set
  where both \texttt{true} and \texttt{false} are memebers with probability
  $\frac{1}{2}$, the result of inputting this into, e.g., \texttt{unit true} would be
  the probability of the value (\texttt{true}) being a member of said set. }


% \todo[inline, color=green!40]{A measure is a linear function $\mu$ from a set A to
%   non-negative real numbers. It also preserves least upper bounds. \\

% Mß = (ß$\to$[0,1])$\to$[0,1]
% The (ß$\to$[0,1]) part describes a probability distribution. 
% We can view our programs as transformations of probability distributions.\\

% "a term e of type ß is translated to a purely functional one [e] which is
% understood as a measure on the same type."}

% \todo[inline]{The w-cpo structure on [0,1]; why is it an w-cpo?\\
% @Bas: What do we need the structure for? \\
% Answer: We just need the w-cpo structur on [0,1] in order to interpret fixed points
% and while loops in the functions to [0,1].}
% \todo[inline]{I am confused by what it says on page 574: First we talk about $\mu$(f)
% for f:A$\to$[0,1] and then we say that $\mu$ is a measure on A. Shouldn't it be on
% probability distributions over A (so A$\to$[0,1])?\\
% Answer: The measure $\mu$ over A is the same as the integral of f. This means that
% $\mu$ has to be applied to a function, but is in reality a measure on A. }

\subsubsection{A monadic interpretation}
\todo[inline, color=green!40]{
  We can represent measures with a monadic structure. This is sensible since once we go
  measure we never go back; once probability is involved in a computation, we will not
  get rid of it again.}
\todo[inline]{Add something about how the measure type now is called \texttt{M}.}

The monadic operators presented here have been formerly introduced by
[...] %\cite{rml-paper}
and satisfy the usual monadic \todo{Footnote too facetious?} properties\footnote{We
  refer the reader who is unfamiliar with monads (or requires proof of the authors'
  knowledge thereof) to an earlier work by the authors, which can be found at
  \url{https://bitbucket.org/Ninijura/functionalprogramming/raw/47de0f3f259370f3214789bbc90511313be451f8/project/report_final.pdf}}.
They are also used by the Mathematical Components compliant Analysis Library\footnote
{\url{https://github.com/math-comp/analysis/tree/master/}} in their representation of
distributions.

\begin{align*}
  \texttt{unit} & :~ \tau\to\texttt{M}\tau\\
                & = \texttt{fun }(x:\tau)\Rightarrow
                  \texttt{fun }(f~:~\tau\to[0,1])\Rightarrow f~x\\
  \texttt{bind} & :~\texttt{M}\tau\to(\tau\to\texttt{M}\sigma)\to\texttt{M}\sigma\\
                & = \texttt{fun }(\mu~:~\texttt{M}\tau)\Rightarrow \texttt{fun }
                  (M~:~\tau\to\texttt{M}\sigma) \Rightarrow\\
                & ~~~~\texttt{fun }(f~:~\sigma\to[0,1])\Rightarrow \mu~ (\texttt{fun
                  }(x~:~\tau)\Rightarrow M~x~f)
\end{align*}
\\
These definitions look big and scary, so let's break them down.
\\ \\
The \texttt{unit} function could be described as the ``wrapper'' that takes a value
and wraps the monad around it. The outermost \todo{Is this the right word for the
\texttt{fun}-keyword)}function binding
takes the value that we want to produce the measure of and remembers it. The second
function binding is to match the type of measures; this is where the probability
distribution is received as input, and where we then give the output of said
distribution function applied to our initial value.

A simple example could be \texttt{unit 5} applied to the uniform distributions of
numbers between 1 and 5. The result would then be 0.2, since that is the probability
of a (pseudo-)random sampling from our measure (we recall that in this case it is
just the characteristic function $\mathbb{I}_{\{5\}}$) and a (psuedo-)random sampling
from the initial distribution coinciding. 
\\ \\
The \texttt{bind} function can be viewed as something transforming the value inside
the monad. 
Let us take it from the inside and out. Clearly the last line of the definition is
the result, the \texttt{M}$\sigma$ part; this is obvious from the types. $\mu$ and
$M$ are the usual arguments to a \texttt{bind} operation, $\mu$ being the initial
value and $M$ the transformation to be applied to it.

We can view the final construction like continuation passing style programming. We
still have a value of type $\tau$ inside the monad before we bind it into a function,
and we want to retain that information in the result of the \texttt{bind}. But we can
not access this information unless we supply the value of type \texttt{M}$\tau$ with
a function of type $\tau \to [0,1]$; this function is the one that $\mu$ is applied
to in the final value. Since the result is of type \texttt{M}$\sigma$, it would make
sense to use its input on something of type $\sigma$ to get something in [0,1], which
would satisfy the output type for the function we apply $\mu$ to.

The final function takes the input of type $\tau$, that $\mu$ will give it,
uses $M$ on it to transform it to something of type \texttt{M}$\sigma$, and then
supplies it with the last piece of the computation, $f$.

This way we retain all of the information that is contained in $\mu$, transform it
with $M$, and lastly transform it with $f$, once that is supplied.

\todo[inline]{Add an example.}


% Packages: comment
\subsection{The functional approach: \rml}\label{sec:rml}
The first language for probabilistic programs implemented in Coq is called \rml
('Randomised monadic language')
and is due to is due toe Philippe Audebaud and Christine Paulin-Mohring. %\cite
\\ \\
\rml could be described as a functional version of the \texttt{while} language with
an interpretation that allows for probabilistic algorithms. The language itself does
not contain probabilistic expressions, but rather makes use of a \texttt{random($n$)}
or \texttt{flip} function giving a uniform distribution of natural numbers between 0
and $n$, and \texttt{true} and \texttt{false}, \todo{check this sentence}respectively.

Since calling either function would be considered a valid \rml term, the result has
to be a measure over natural numbers (in the case of \texttt{random($n$)}) or
booleans (in the case of \texttt{flip}).\\
\\
The expressions that our language consists of \todo{Is this parenthetical needed?}(we
recall that it is a functional language, so there are only expressions, no
statements) are as follows:

\begin{align*}
  exp~::= ~ x~\vert ~ c~\vert ~ \texttt{if }b\texttt{ then }e_1\texttt{ else} e_2~
  \vert ~ \texttt{let }x = e_1 \texttt{ in }e_2~\vert ~ f~e_1~\dots~e_n
\end{align*}

Here $x$ refers to a variable name previously bound in a let-binding, and $c$ refers
to a primitive constant. Since Paulin-Mohring and Adebaud don't give a clear
definition of what a constant can be, it makes sense to assume, that it can be any
Coq term.

The $f$ in function application can be a \todo{quote}``primitive or a user-defined
function'', where primitive would be \texttt{random($n$)} or \texttt{flip}, and a
user-defined function should be specified by \texttt{let }$f~x_1~\dots~ x_n= e$,
according to the language specification. Recursive functions can be defined with the
keyword \texttt{let rec}.

The monadic interpretation $[e]:\texttt{M}\tau$ of a term $e:\tau$ is given in
\todo{What the hell is wrong with figure numbering?}figure \ref{fig:rml-monad}.

\begin{figure}[h]
  \label{fig:rml-monad}
  \begin{center}
    \begin{tabular}{|c|c|}
      \hline
      \rml term $e~:~\tau$ & Coq value $[e]~:~\texttt{M}\tau$\\
      \hline
      $v$ & \texttt{unit }$v ~~ v$ variable or constant\\ & \\
      $\texttt{let }x=a\texttt{ in } b$ & $\texttt{bind }[a]~(\texttt{fun } x
                                          \Rightarrow [b])$\\ & \\
      $f~a_1\dots a_n$ & $\texttt{bind }[a_1]~(\texttt{fun } x_1 \Rightarrow \dots
                         \texttt{bind }[a_n]~$ \\
                           & $(\texttt{fun } x_n \Rightarrow [f]~x_1
                             \dots x_n) \dots ) $\\ & \\
      \texttt{if $b$ then $a_1$ else $a_2$} &  $\texttt{bind } [b]~(\texttt{fun }
                                              x~:~\texttt{bool}) \Rightarrow$\\
                           & (\texttt{if $x$ then $[a_n]$ else $[a_2]$})\\
      \hline
    \end{tabular}\\
    \caption{Monadic interpretation of \rml terms as presented in [...]}%\cite{rml-paper}
  \end{center}
\end{figure}

\subsection{\textsc{EasyCrypt} and \texttt{pwhile} (or 'The imperative approach')}\label{sec:pwhile}
% Here we should give a quick description of EasyCrypt and present pwhile
\textsc{EasyCrypt} is a framework that has been developed in order to help in the
construction of machine-checkable proofs about cryptographic constructions and
protocols. %\cite{ https://www.easycrypt.info/documentation/refman.pdf}
A standard approach to this kind of proofs is based on so-called games; in
\textsc{EasyCrypt} cryptographic algorithms as well as games are modelled as
\textit{modules} consisting of procedures written in a simple imperative language
called \texttt{pwhile}. The \texttt{p} in \texttt{pwhile} stands for
``probabilistic'', so in total the name refers to a probabilistic extension of the
well-known minimalistic \texttt{while} language.

We will in this section give an overview of the language as well as its
interpretation in Coq, which is due to a development by Pierre-Yves Strub
\footnote{https://github.com/strub/xhl}. We will not concern ourselves with the
module system of \textsc{EasyCrypt} since the focus of the present development is
on probabilistic languages and their interpretation rather than their use.\\
\\
\texttt{pwhile} consists of the following expressions and commands: 
\begin{align*}
  exp ::=~& x ~\vert ~ const ~\vert ~ \texttt{prp ($p$ : pred mem)}~\vert ~ e_1\ e_2\\
  cmd ::=~& \texttt{abort} ~\vert ~ \texttt{skip} ~\vert ~ x := e ~\vert ~ x\ \$= e\\
  \vert ~ & \texttt{if } b \texttt{ then } c_1 \texttt{ else } c_2 ~\vert ~
            \texttt{while } b \texttt{ do } c ~\vert ~ c_1 ; c_2
\end{align*}

The embedding of \texttt{pwhile} in Coq is a so-called shallow embedding, which means
that we use Coq terms and types as part of programs in \texttt{pwhile}. This is used
in order to form expressions: Constants in \texttt{pwhile} are Coq constants, hence
an expression in \texttt{pwhile} can have any Coq type. In the implementation,
expressions are parameterised by their type.

Most of the above constructs are fairly standard and should be known to most
readers. We give a full formal semantics in Figure \todo{Insert reference to semantics-figure}.

\todo[inline]{Write the semantics for \texttt{pwhile}.}

In addition to the standard expressions and commands, \texttt{pwhile} has the
expression \texttt{prp $p$}, which we will have a look at here.
\texttt{prp} takes a single argument of type \texttt{pred mem}. This is a Coq type
specified with the type constructor \texttt{pred} = $\forall \tau~:~\tau \to
\mathbb{B}$ applied to the type of memories defined in the \texttt{xhl}
development. The predicate over memories that is \texttt{prp}s argument is mapped
over the working memory at the time of evaluation.

For more clarity, we will look at an example. Let us take the situation where we only
want to proceed with a computation, if a certain variable, $x$ is defined in the
memory; we want to access $x$, but want to avoid our program crashing if $x$ has not
been defined. We now write the function \texttt{x\_defined} that, given a memory,
returns true if $x$ is defined in said memory and false otherwise. By branching on
\texttt{prp x\_defined}, we can now make sure that we only take the branch accessing
$x$ if it is present in the memory and do not end up with a program that may
crash. \\
\\
At this point a comment about ``crashing'' programs is in order. There are multiple
ways in which a program can lead to an undefined result: encountering undefined
behaviour, non-termination, and the \texttt{abort} command. The interpretation of all
of these is the same: We recall that the result of interpreting a \texttt{pwhile}
program in Coq is a probability distribution over memories; now the result of
interpreting a ``crash'' is by simply returning the \todo{is this the right word
  choice? It doesn't seem that that's what a null distribution is. But the keyword
  use is \texttt{dnull}.}null-distribution over memories.\\
\\


\section{Our approach (Ready draft: 03.06.)}\label{sec:approach}
% Goal: 6-12 pages

% Describe the translation from while to functional (+recursion), to lambda-calculus,
% to an interpretation in omega-cpos.

% We planned on making an interpretation of Rml in Coq and then translating the xhl
% implementation of pwhile to our abstract syntax. 

\todo[inline, color=green!40]{The goal of the present project was to gain an
  actionable understanding of \rml and \texttt{pwhile}, their respective
  interpretations, theoretic background, and similarities and differences between
  them. Our approach was to define a translation between \texttt{pwhile} and \rml as
  well as an interpretation of \rml, and subsequently show that translating from
  \texttt{pwhile} to \rml and interpreting the resulting program would lead to the
  same interpretation as interpreting the \texttt{pwhile} program directly.

  This approach allowed us to get acquainted with both languages as well as the
  difficulties in interpretation that both of them share.}

\todo[inline]{Triangle figure.}

\todo[inline, color=green!40]{In this section we will concern ourselves with the
  translation between \texttt{pwhile} and \rml, as well as a full interpretation of
  \rml. We will first have a look at deterministic versions of both in order to
  define the main part of the translations (Sections \ref{sec:while-to-fun},
  \ref{sec:fun-to-lambda}, \ref{sec:lambda-interp}, and \ref{sec:while-interp}), and
  afterwards we will have a look at how to add probabilistic constructs into all
  translations (Section \ref{sec:probab}).

  According to Boileau, ``what one understands well is expressed clearly'', and there
  are few ways to say things as concisely as in code. Due to this, we decided to
  implement part of the content of the present section in Coq and section
  \ref{sec:contrib} will give a comprehensive overview of our development.} 


\subsection{Translating \texttt{while} to a functional
  language}\label{sec:while-to-fun} 
% 
In order to do the translations properly, let us first have a look at a translation
from the simple, widely known \texttt{while} language to a simple functional language
resembling \rml. The thought behind this is that once this translation is in place,
all we have to do to translate \texttt{pwhile} to \rml is to add probability.

\begin{align}
  \label{eq:while}
  exp~  ::=~~ & x \vert n \vert \texttt{true} \vert \texttt{false} \vert f~x \\
  stm~  ::=~~ & \texttt{skip} \vert x := e
               \vert \texttt{if } e \texttt{ then } s_1 \texttt{ else } s_2
               \vert \texttt{while } e \texttt{ do } s \vert s_1;s_2
\end{align}

The syntax of our functional language is the same as \rml modulo the pre-defined
probabilistic functions.

The translation of expressions is completely straightforward: variables are mapped to
variables, constants to constants, and function applications to function applications. 

In order to translate statements we choose a set of SML-style matching rules; this
choice is due to the translation of sequences being dependent on what the first
statement is. We will in the following write the translation of a \texttt{while}
statement $s$ to an expression in our functional language as $\llbracket s
\rrbracket$. 

The result of a computation in \texttt{while} is the state of a memory, while the
result of a functional computation is a value. A simple way to make up for this
difference is by choosing a variable name that is designated the return variable and
encapsulates the information we are interested in after the computation. This is the
result of a program translated from \texttt{while} to our functional language; in the
following we choose $x_r$ as the symbol for the chosen return variable. 

\begin{align}
  \label{eq:transwhile}
  \texttt{skip}~;~s ~\mapsto~ & \llbracket s \rrbracket\\
  \notag\\
  \texttt{skip}     ~\mapsto~ & x_r\\
  \notag\\
  x := e~;~s        ~\mapsto~ & \texttt{let } x := e \texttt{ in }\llbracket s \rrbracket\\
  \notag\\
  x_r := e          ~\mapsto~ & e \\
  \notag\\
  x := e            ~\mapsto~ & x_r \\
  \notag\\
  (\texttt{if } e \texttt{ then } s_1 \texttt{ else } s_2) ~;~s_3
                    ~\mapsto~ & \texttt{if } e \\
                    &  \texttt{ then } \llbracket s_1 ~;~ s_3 \rrbracket\notag\\
                    & \texttt{ else } \llbracket s_2 ~;~ s_3 \rrbracket \notag\\
  \notag\\
  \texttt{if } e \texttt{ then } s_1 \texttt{ else } s_2
                    ~\mapsto~ & \texttt{if } e
                                  \texttt{ then } \llbracket s_1 \rrbracket
                                  \texttt{ else } \llbracket s_2 \rrbracket \\
  \notag
\end{align}
\begin{align}
  (\texttt{while } e \texttt{ do } s_1) ~;~ s_2
                    ~\mapsto~ & \texttt{let rec } f~x :=
                                  \texttt{if } e \label{eq:while1}\\
                    & \phantom{{}=11111111111} \texttt{ then } \llbracket s_1 ~;~ f~x \rrbracket \notag\\
                    &\phantom{{}=11111111111}\texttt{ else } \llbracket s_2 \rrbracket\notag\\
                    & \texttt{ in } f~0 \notag \\
  \notag\\
  \texttt{while } e \texttt{ do } s_1
                    ~\mapsto~ & \texttt{let rec } f~x :=
                                 \texttt{if } e \label{eq:while2}\\
                    & \phantom{{}=11111111111}\texttt{ then } \llbracket s_1 ~;~ f~x \rrbracket\notag\\
                    & \phantom{{}=11111111111}\texttt{ else } x_r \notag\\
                    & \texttt{ in } f~0\notag
\end{align}

Note that in \ref{eq:while1} and \ref{eq:while2} we create recursive functions with a
name and an argument, both of which are not present in the while construct we
translate from. This means that we have to be careful about the translation: Both $f$
and $x$ have to be chosen fresh; and even fresher than that, they can not occur in
the body of the while loop we are translating either, because that would break the
recursive call.

Further notice that the recursive functions are always called with a dummy
argument. This is because they act as procedures, but since our syntax requires an
argument for recursive definitions, we give a dummy argument.


\subsection{Translation from Rml to typed
  $\mathbf{\lambda}$-calculus}\label{sec:fun-to-lambda}  
\todo[inline, color=red]{This section is preliminary and needs either huge changes or deletion
  before the report is finalised. }
\begin{center}
  \begin{tabular}{|c|c|}
    \hline
    Rml & @sRml A \\ \hline
    Var $(x,A)$ & sVar $x$ \\
    Const $A$ $c$ & sConst c \\
    Let $(x,T)$ $e_1$ $e_2$ & $e_2'$ \\
    If $b$ $e_1$ $e_2$ & sIf $b'$ $e_1'$ $e_2'$ \\
    Fun $(x,T)$ $e$ & sFun $S$ $(x,T)$ $e'$ \\
    App $T$ $e_1$ $e_2$ & sApp $T$ $e_1'$ $e_2'$ \\
    Let rec $T$ $S$ $f$ $x$ $e_1$ $e_2$ & sFix $T$ $S$ $f$ $x$ $e_1'$ $e_2'$ \\ \hline
  \end{tabular}
\end{center}

\begin{center}
  \begin{tabular}{|c|c|c|}
    \hline
    @sRml A & typed $\lambda$-calculus & distr \\ \hline
    sVar $x$ & $x : A$ & dunit (lookup x) \\
    sConst c & $c : A$ & dunit c \\
    sFun $S$ $(x,T)$ $e'$ & $(\lambda x : T, e : S) : T \rightarrow S$ & $\backslash x \rightarrow \text{dunit}~e$  \\
    sApp $T$ $e_1'$ $e_2'$ & $(e_1 : T \rightarrow A)~(e_2 : T) : A$ & $e_1' \bind \backslash e_1'' \rightarrow e_2' \bind \backslash e_2'' \rightarrow \text{dunit}~(e_1''~e_2'')$ \\
    sFix $T$ $S$ $f$ $x$ $e_1'$ $e_2'$ & $(\lambda f : T \rightarrow S, e_2)~(Y~(\lambda f : T \rightarrow S, (\lambda x : T, e_1~x))) : A$ & $(\backslash f \rightarrow e_2) (\backslash x \rightarrow \text{dlim}~(\text{ubn}~e_1~x))$ \\ \hline
  \end{tabular}
\end{center}

\subsection{Example: Fact}
Expression:
\begin{align*}
\mathtt{Let\_rec}&~(f,\mathbb{N} \rightarrow \mathbb{N})~(x,\mathbb{N})~\\
  (&\mathtt{If}~(x = 0)~(1)~(x * f~(x-1)))\\
  (&f~3)
\end{align*}
Simple form:
\begin{align*}
  & \mathtt{sFix}~f~x \\
  & \quad (\mathtt{sIf}~(x = 0)~1~(x * f~(x - 1)))\\
  & \quad (f~3)
\end{align*}
Typed lambda expressions:
\[(\lambda f : \mathbb{N} \rightarrow \mathbb{N}, f~3)~(Y (\lambda f : \mathbb{N} \rightarrow \mathbb{N}, \lambda x : \mathbb{N}, (x = 0)~(1)~(x * f~(x-1))))\]
Distribution:
\[\backslash\mathtt{dlet}\_(f \leftarrow \mathtt{dunit}~(\lambda x, \backslash\mathtt{dlim} (\backslash\mathtt{ubn}~(\lambda f, (x = 0)~(1)~(x * f~(x-1))))))~(f~3)\]


\subsection{Interpreting $\lambda$-calculus in the space of
  $\omega$-cpos}\label{sec:lambda-interp} 
\todo[inline]{What do $\omega$-cpos have to do with this?}


\subsection{Interpreting \texttt{while} directly}\label{sec:while-interp}
\todo[inline]{This should probably mainly refer back to the interpretation of
  \texttt{pwhile}.}

\subsection{Adding probabilistic definitions}\label{sec:probab}


\subsection{All translations (forward)}
\todo[inline]{What is the point of this section? }
\begin{center}
    \resizebox{1.05\linewidth}{!}{
      \begin{tabular}{|c|c|}
        \hline
        Rml & @sRml A \\ \hline
        Var $(x,A)$ & sVar $x$ \\
        Const $A$ $c$ & sConst c \\
        Let $(x,T)$ $e_1$ $e_2$ & $e_2'$ \\
        If $b$ $e_1$ $e_2$ & sIf $b'$ $e_1'$ $e_2'$ \\
        Fun $(x,T)$ $e$ & sFun $S$ $(x,T)$ $e'$ \\
        App $T$ $e_1$ $e_2$ & sApp $T$ $e_1'$ $e_2'$ \\
        Let rec $T$ $S$ $f$ $x$ $e_1$ $e_2$ & sFix $T$ $S$ $f$ $x$ $e_1'$ $e_2'$ \\ \hline
      \end{tabular}
    }
\end{center}

\begin{center}
  \resizebox{1.05\linewidth}{!}{
    \begin{tabular}{|c|c|c|}
      \hline
      @sRml A & typed $\lambda$-calculus & distr \\ \hline
      sVar $x$ & $x : A$ & dunit (lookup x) \\
      sConst c & $c : A$ & dunit c \\
      sFun $S$ $(x,T)$ $e'$ & $(\lambda x : T, e : S) : T \rightarrow S$ &  \\
      sApp $T$ $e_1'$ $e_2'$ & $(e_1 : T \rightarrow A)~(e_2 : T) : A$ & $e_1' \bind \backslash e_1'' \rightarrow e_2' \bind \backslash e_2'' \rightarrow \text{ret}~(e_1'~e_2')$ \\
      sFix $T$ $S$ $f$ $x$ $e_1'$ $e_2'$ & $(e_2 : (T \rightarrow S) \rightarrow A)~(Y~(e_1 : (T \rightarrow S) \rightarrow T \rightarrow S) : T \rightarrow S) : A$ & $(\backslash f \rightarrow e_2) (\backslash x \rightarrow \mathtt{dlim}~(\mathtt{ubn}~e_1~x))$ \\ \hline
    \end{tabular}
  }
\end{center}
Problem we get a function \(f : A \rightarrow distr~B\), instead of \(f : distr~(A \rightarrow B)\) (solution bind)





\section{Our contribution (Draft: 03.06; Finished 10.06.)}\label{sec:contrib}
% Goal: 6-12 pages
% What we actually did.

% We implemented an abstract syntax for Rml in Coq

% We tried to translate from pwhile to said Rml (syntax to syntax)

% We were able to interpret Rml modulo general recursion, using a probability monad.

% We tried implementing general recursion with the extra step of translating to the
% typed lambda calculus and using a fixpoint combinator.

\subsection{Our implementation of \rml}
The data structure used to represent Rml terms is as follows:
\begin{center}
  \begin{minipage}{0.7\linewidth}
    \begin{lstlisting}[language=coq]
Inductive Rml :=
| Var : (nat * Type) -> Rml
| Const : forall (A : Type), A -> Rml
| Let_stm : (nat * Type) -> Rml -> Rml -> Rml
| Fun_stm : Type -> (nat * Type) -> Rml -> Rml
| If_stm : Rml -> Rml -> Rml -> Rml
| App_stm : Type -> Rml -> Rml -> Rml
| Let_rec : Type -> Type -> nat -> nat -> Rml -> Rml -> Rml.
    \end{lstlisting}
  \end{minipage}
\end{center}
We use all cog types, as possible types of Rml expressions, since there are no real restrictions on the types. We encode variables, as a type and a natural number, so two variables are the same only if they have the same number and refer to the same type.
\\ \\
We have defined a relation \wellformed, that checks that no variables are escaping the scope of an Rml program, that is there is always a binding for an expression of type \(\mathtt{Var}~p\). We furthermore define a relation \valid, which checks that a given Rml expression can be typed under a given type. We have shown that if a Rml program is valid then it is well formed. We have then constructed a simplified form of Rml called sRml (for simple Rml), to make it easier to reason about and evaluate expressions, with the following data structure:
\begin{center}
  \begin{minipage}{0.7\linewidth}
    \begin{lstlisting}[language=coq]
Inductive sRml {A : Type} :=
| sVar : nat -> sRml
| sConst : A -> sRml
| sFun : forall C (p : nat * Type), A = (p.2 -> C) -> @sRml C -> sRml
| sIf : @sRml bool -> sRml -> sRml -> sRml
| sApp : forall T, @sRml (T -> A) -> @sRml T -> sRml
| sFix : forall B (nf nx : nat), @sRml (B -> A) -> @sRml B -> sRml.
    \end{lstlisting}
  \end{minipage}
\end{center}
That is Rml where we remove expressions with variables, from \texttt{let\_stm} statements (not \texttt{let\_rec} statements). We then show that given a valid typing of an Rml expression, we can simplify that expression, and maintain the valid typing (under the same type). With this we can make an interpreter from an interpreter of sRml, which can be constructed as (for continuations). We have a similar function for Rml, using the posibility distributions as interpretations. We see similar patterns arising, since both interpretations are monadic.

\section{Comparisons and future work (Finished 12.06.)}
% Goal: 2-4 pages
% What the section header says


\section{Conclusion (Finished 12.06.)}
% Goal: 1-2 pages



\newpage
\section{Appendix}
Example - Error: Stack Overflow.
\begin{lstlisting}[language=coq]
Fixpoint replace_all_variables_aux_type
         A (x : Rml) (env : seq (nat * Type * Rml))
         (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
         `{x_valid : @rml_valid_type A (map fst env) fl x} : @sRml A
                                                                            
with replace_all_variables_aux_type_const
       A0 A a (env : seq (nat * Type * Rml))
       (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
       `{x_valid : @rml_valid_type A0 (map fst env) fl (Const A a)} : @sRml A0
with replace_all_variables_aux_type_let
       A p x1 x2 (env : seq (nat * Type * Rml))
       (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
       `{x_valid : @rml_valid_type A (map fst env) fl (Let_stm p x1 x2)} : @sRml A
with replace_all_variables_aux_type_fun
       A T p x (env : seq (nat * Type * Rml))
       (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
       `{x_valid : @rml_valid_type A (map fst env) fl (Fun_stm T p x)} : @sRml A
with replace_all_variables_aux_type_if
       A x1 x2 x3 (env : seq (nat * Type * Rml))
       (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
       `{x_valid : @rml_valid_type A (map fst env) fl (If_stm x1 x2 x3)} : @sRml A
with replace_all_variables_aux_type_app
       A T x1 x2 (env : seq (nat * Type * Rml))
       (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
       `{x_valid : @rml_valid_type A (map fst env) fl (App_stm T x1 x2)} : @sRml A
with replace_all_variables_aux_type_let_rec A T T0 n n0 x1 x2 (env : seq (nat * Type * Rml))
     (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
     `{x_valid : @rml_valid_type A (map fst env) fl (Let_rec T T0 n n0 x1 x2)} : @sRml A.
Proof.
  (** Structure **)
  {
    induction x ; intros ; refine (sVar (0,A)).
  }
  
  all: refine (sVar (0,A)).  
Defined.
\end{lstlisting}

\end{document}
