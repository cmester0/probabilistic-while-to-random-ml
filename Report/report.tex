% -------------------------------------------------------------
% Document setup 
% -------------------------------------------------------------
\documentclass[11pt, leqno, titlepage]{article}
\usepackage{graphicx}
%\usepackage[left=30mm,right=30mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[page]{appendix}
\usepackage[noadjust]{cite}
\usepackage[nottoc]{tocbibind}
% -------------------------------------------------------------
% Notation aids 
% -------------------------------------------------------------
\usepackage{amsmath} % American Mathematical Society math-notations
\usepackage{amssymb} % American Mathematical Society math-symbols
\usepackage{amsthm}  % For good looking definitions and theorems
\usepackage{stmaryrd} % For interpretation bracket (and maybe other stuff)
\usepackage{listings}
\usepackage{tikz}
\usetikzlibrary{cd}

% -------------------------------------------------------------
% For convenient development
% -------------------------------------------------------------
\usepackage{todonotes}

\lstdefinelanguage{Coq}{ 
%
% Anything betweeen $ becomes LaTeX math mode
mathescape=true,
%
% Comments may or not include Latex commands
texcl=false, 
%
% Vernacular commands
morekeywords=[1]{Section, Module, End, Require, Import, Export,
  Variable, Variables, Parameter, Parameters, Axiom, Hypothesis,
  Hypotheses, Notation, Local, Tactic, Reserved, Scope, Open, Close,
  Bind, Delimit, Definition, Let, Ltac, Fixpoint, CoFixpoint, Add,
  Morphism, Relation, Implicit, Arguments, Unset, Contextual,
  Strict, Prenex, Implicits, Inductive, CoInductive, Record,
  Structure, Canonical, Coercion, Context, Class, Global, Instance,
  Program, Infix, Theorem, Lemma, Corollary, Proposition, Fact,
  Remark, Example, Proof, Goal, Save, Qed, Defined, Hint, Resolve,
  Rewrite, View, Search, Show, Print, Printing, All, Eval, Check,
  Projections, inside, outside, Def},
%
% Gallina
morekeywords=[2]{forall, exists, exists2, fun, fix, cofix, struct,
  match, with, end, as, in, return, let, if, is, then, else, for, of,
  nosimpl, when},
%
% Sorts
morekeywords=[3]{Type, Prop, Set, true, false, option},
%
% Various tactics, some are std Coq subsumed by ssr, for the manual purpose
morekeywords=[4]{pose, set, move, case, elim, apply, clear, hnf,
  intro, intros, generalize, rename, pattern, after, destruct,
  induction, using, refine, inversion, injection, rewrite, congr,
  unlock, compute, ring, field, fourier, replace, fold, unfold,
  change, cutrewrite, simpl, have, suff, wlog, suffices, without,
  loss, nat_norm, assert, cut, trivial, revert, bool_congr, nat_congr,
  symmetry, transitivity, auto, split, left, right, autorewrite},
%
% Terminators
morekeywords=[5]{by, done, exact, reflexivity, tauto, romega, omega,
  assumption, solve, contradiction, discriminate},
%
% Control
morekeywords=[6]{do, last, first, try, idtac, repeat},
% % Custom
morekeywords=[8]{Var, Const, Let_stm, Fun_stm, If_stm, App_stm, Let_rec, Random, Flip,
sVar, sConst, sFun, sIf, sApp, sFix, sRandom, sFlip},
% Comments delimiters, we do turn this off for the manual
morecomment=[s]{(*}{*)},
%
% Spaces are not displayed as a special character
showstringspaces=false,
%
% String delimiters
morestring=[b]",
morestring=[d]Â’,
%
% Size of tabulations
tabsize=3,
%
% Enables ASCII chars 128 to 255
extendedchars=false,
%
% Case sensitivity
sensitive=true,
%
% Automatic breaking of long lines
breaklines=false,
%
% Default style fors listings
basicstyle=\small,
%
% Position of captions is bottom
captionpos=b,
%
% flexible columns
columns=[l]flexible,
%
% Style for (listings') identifiers
identifierstyle={\ttfamily\color{black}},
% Style for declaration keywords
keywordstyle=[1]{\ttfamily\color{violet}},
% Style for gallina keywords
keywordstyle=[2]{\ttfamily\color{green}},
% Style for sorts keywords
keywordstyle=[3]{\ttfamily\color{blue}},
% Style for tactics keywords
keywordstyle=[4]{\ttfamily\color{blue}},
% Style for terminators keywords
keywordstyle=[5]{\ttfamily\color{red}},
%Style for iterators
%keywordstyle=[6]{\ttfamily\color{dkpink}},
keywordstyle=[7]{\ttfamily\color{orange}},
keywordstyle=[8]{\ttfamily\color{teal}},
keywordstyle=[9]{\ttfamily\color{magenta}},
% Style for strings
stringstyle=\ttfamily,
% Style for comments
commentstyle={\ttfamily\color{purple}},
%
%moredelim=**[is][\ttfamily\color{red}]{/&}{&/},
literate=
    {\\forall}{{\color{dkgreen}{$\forall\;$}}}1
    {\\exists}{{$\exists\;$}}1
    {<-}{{$\leftarrow\;$}}1
    {=>}{{$\Rightarrow\;$}}1
    {==}{{\code{==}\;}}1
    {==>}{{\code{==>}\;}}1
%    {:>}{{\code{:>}\;}}1
    {->}{{$\rightarrow\;$}}1
    {<->}{{$\leftrightarrow\;$}}1
    {<==}{{$\leq\;$}}1
    {\#}{{$^\star$}}1 
    {\\o}{{$\circ\;$}}1 
    {\@}{{$\cdot$}}1 
    {\/\\}{{$\wedge\;$}}1
    {\\\/}{{$\vee\;$}}1
    {++}{{\code{++}}}1
    {~}{{\ }}1
    {nat}{{$\mathbb{N}$}}1
    {forall}{{$\forall$}}1
    {\@\@}{{$@$}}1
    {\\mapsto}{{$\mapsto\;$}}1
    {\\hline}{{\rule{\linewidth}{0.5pt}}}1
%
}[keywords,comments,strings]

\lstnewenvironment{coq}{\lstset{language=Coq}}{}

% pour inliner dans le texte
\def\coqe{\lstinline[language=Coq, basicstyle=\small]}
% pour inliner dans les tableaux / displaymath...
\def\coqes{\lstinline[language=Coq, basicstyle=\scriptsize]}

% \lstdefinelanguage{rml}{
% }

% \lstdefinelanguage{pwhile}{
% }
\lstdefinelanguage{pwhile}{
}
% -------------------------------------------------------------
% Prettyfying
% -------------------------------------------------------------
\usepackage[hidelinks]{hyperref}

\usepackage{xcolor}
% -------------------------------------------------------------

\author{Kira Kutscher - 201509720 \\
  Lasse Letager Hansen - 201508114
}
\date{17th of June 2019}
\title{Exploring interpretations \\of\\ probabilistic algorithms\\
  using measure theory \\in Coq}
%

\newcommand{\set}[1]{\{#1\}}

\newcommand{\Rml}{\textcolor{orange}{\mathtt{Rml}}}
\newcommand{\sRml}{\textcolor{orange}{\mathtt{sRml}}}
\newcommand{\Type}{\textcolor{blue}{\mathtt{Type}}}
\newcommand{\wellformed}{\texttt{well\_formed}}
\newcommand{\valid}{\texttt{rml\_valid\_type}}
\newcommand{\bind}{>\!\!>\!\!=}

\theoremstyle{definition}
\newtheorem{thm}{Theorem}
\newtheorem{defn}[thm]{Definition}

\renewcommand{\thefigure}{\thesection.\arabic{figure}}

\begin{document}

% -------------------------------------------------------------

\newcommand\rml{$\mathcal{R}$\texttt{ml}} % for a pretty version of "Rml"
\newcommand\rmlx{$\mathcal{R}$\texttt{ml}*}
\newcommand\srml{\texttt{s}\rml}
\newcommand\M{\texttt{M}} % for the M representing monads

% -------------------------------------------------------------

\input{titlepage.tex}

\abstract{Abstract here. }
\newpage

\tableofcontents
\newpage

% ------------------------------------------------------------- 

\section{Introduction (READY)}
Probabilistic algorithms are widely used in computer science, especiallly in the
fields of cryptography and security. Because of their many applications, reliable
proofs of the correctness and/or security of such algorithms are desirable. 

A number of developments exists that attempt to make this kind of proofs easier and
more secure, but with such developments the next question is if the implementation is
correct and the logic consistent.  We will in the present work focus on developments
in the Coq proof assistant, since it is one of the most widely used and most probably
correct proof assistants currently in existence.

\subsection{The Coq proof assistant}
The Coq proof assistant was developed in 1984 \cite{coq-proof-ass} and its logic,
originally based on the Calculus of Constructions, was extend to the Calculus of
Inductive Constructions by Christine Paulin in 1991.  It has been under constant
development ever since it was first published and many bugs have since been found and
fixed, making Coq one of the most reliable and trusted proof environments.

The reader is not expected to have an understanding of Coq, though it might be
helpful in Section \ref{sec:contrib}, which deals with our Coq development. 

\subsection{Previous work}
For our development we oriented ourselves at the landmarks of previous frameworks
that have been built for proofs of probabilistic algorithms in Coq. We looked at
three approaches of designing probabilistic languages and a framework for proof about
programs in these languages; two of them are functional, \rml\ \cite{rml-paper} and
FCF \cite{fcf}, and the last one, \texttt{pwhile}, is imperative \cite{easy-crypt}.

Both FCF and \rml\ are developments that have been implemented in Coq, but are not
available to use: The FCF development is implemented in an older version of Coq, so
it does not run on the current version; and \rml\ has been implemented, but the
development is not available. 
\texttt{pwhile} originated as a Coq development, then took wings as the language used
for probabilistic algorithms in \textsc{EasyCrypt}, and is currently being brought
back to Coq with the \texttt{xhl} development (cf. Section \ref{sec:pwhile}).

\subsection{Roadmap}
This work built around the \texttt{xhl} implementation of \texttt{pwhile} as well as
the description of \rml\ that can be found in \cite{rml-paper}. We aim at analysing
differences and similarities between both languages and proving them equivalent. 

We will begin our journey with introducing the theory necessary to understand both
languages (Section \ref{sec:theory}); this includes the domain-theoretic
interpretation of general recursion (Section \ref{sec:fixp-iter}) as well as a
monadic interpretation of probabilistic programs based on measure theoretic concepts
(Section \ref{sec:prob-interp}). We will also have a closer look at \rml\ (Section
\ref{sec:rml}) and \texttt{pwhile} (Section \ref{sec:pwhile}).

We will then develop an approach to translating program from \texttt{pwhile} to \rml\
and proving their interpretations equivalent (Section \ref{sec:approach}).

Lastly we will present our own implementation of \rml\ and its interpretation
(Section \ref{sec:contrib}), we will compare it with the previously discussed
approaches and reflect on how to meaningfully expand the development in Section
\ref{sec:future}. Afterwards we will conclude with Section \ref{sec:conclusion}.


\section{Theory and existing frameworks (READY)} 
\label{sec:theory}
% Goal: 6-12 pages

Our work focuses on interpretations of possibly non-terminating probabilistic
computations encoded in Coq. As mentioned earlier, Coq is widely trsuted; it is,
however, also known to be notoriously difficult to code things in due to a strict
type system that requires determinism and certain termination of all programs written
in it. Obviously these two are not the optimal conditions for running probabilistic
algorithms that may not terminate.

This means that we need a way to encode an interpretation general recursion (or
iteration) as well as randomness in such a way that we can still reason about our
programs in the proof system of Coq without having to run them.

We will in this section present a monadic interpretation into probability
distribution over the outcome of a randomised program as well as a way of
interpreting general recursion.

In this section we will have a look at how to use complete partial orders to
interpret general recursion (Section \ref{sec:cpos}), and how we can represent the
result of a probabilistic computation using a monadic interpretation of probability
measures (Section \ref{sec:prob-interp}. Afterwards we will move on to presenting two
different developments that have worked with probabilistic languages in Coq: the
functional \rml\ (Section \ref{sec:rml}) and the imperative \texttt{pwhile} (Section
\ref{sec:pwhile}).

\subsection{Complete partial orders}\label{sec:cpos}
% Describe cpos, omega-cpos, and dcpos
% partial order: a set with an ordering relation, but not every two elements have to
% be comparable

A partially ordered set (poset) is a set with an associated binary ordering relation
$\leq$ which is both reflexive and transitive. The order is partial when the ordering
relation is not defined on every pair of elements in the set.

There exist a number of different completeness properties that a poset can have.
We will here have a look at $\omega$-complete partial orders, which we will use in
order to interpret general recursion and probabilistic programs. 

\begin{defn}
  \textit{$\omega$-complete partial order ($\omega$-cpo)}\\
  An $\omega$-cpo is a partially ordered set that, additionally, has a distinct least
  element and where there exist least upper bounds on all monotonic sequences. 
\end{defn}

\subsubsection{Recursive definitions as fixed point iterations}
\label{sec:fixp-iter}
% Describe the fixpoint interpretation of recursive/iterative definitions

Before using $\omega$-cpos to interpret recursion, let us first have a look at some
interesting things that our definition entails.

A monotonic sequence on an $\omega$-cpo $X$ can be viewed as a monotonic function
$f~:~\mathbb{N} \xrightarrow{m} X$ where $f(n)$ is the $n$th element of the sequence (or the
least upper bound of the sequence for $n$ larger than the length of the sequence, if the sequence is finite).\\
\\
% Standard definition of fixed points
There is a standard way of defining fixed point iterations on an $\omega$-cpo: \cite{rml-paper}

Consider an operator $F~:~X \xrightarrow{m} X$ on some $\omega$-cpo $X$; with this we
define the monotonic sequence $F_i \mapsto \underbrace{ F(F(\dots F}_{i \text{
    times}} (0_X) \dots))$ of repeated application of $F$ to the least element of $X$.
By our choice of $F$ and the definition of $\omega$-cpos, it is clear that there has
to exist a least upper bound on $F_i$. This least upper bound is the fixed point of
$F$ and it will hold that $\texttt{fix } F = F(\texttt{fix }F)$ if $F$ is
continuous. 
% @Bas: Where do we need non-continuous functions?

% How it extends to function spaces
For an $\omega$-cpo with underlying set $B$ we can also define an $\omega$-cpo on
functions from any set $A$ whose co-domain is $B$.

To reiterate the definition, let us think of what we need for an $\omega$-cpo. We
need an ordering relation, a least element, and a least upper bound operation. Those
can be defined as follows:
\begin{align*}
  f\leq_{A \to B} g \Leftrightarrow \forall x: f(x) \leq_B g(x) & ~~~\textit{(pointwise order)}\\
  0_{A\to B} := f(x) = 0_B & ~~~\textit{(least element)}\\
  \texttt{lub}_{A\to B} f_n := \texttt{lub}_B(f_n(x)) & ~~~\textit{(least upper
                                                               bound operation)}
\end{align*}


% How this can be used to interpret recursion
The result of an interpretation of programs in the language of discourse will be in
an $\omega$-cpo, so according to the above discussion functions will have an
$\omega$-cpo structure as well. Together with the above definition of fixed points we
can use this structure to interpret general recursive definitions. 

We define a functional, $F$, taking as input a function and ``adding a step to it''.
Let us look at the example of the factorial function $f(n) = n!$ \cite{haskell}.
The recursive definition is well known:
$$fac(n) := \texttt{ if } n = 0 \texttt{ then }1\texttt{ else } n\cdot fac(n-1)$$

For the interpretation of this definition, we want to define $F~:~(\mathbb{N} \to
\mathbb{N}) \to (\mathbb{N} \to \mathbb{N})$ in such a way that its fixed point is
the same as the above recursive definition. We choose
$$F(g(n)):=\texttt{ if }n=0\texttt{ then }1\texttt{ else }n\cdot g(n-1)$$
Where $F_0(n)$ is $0_{\mathbb{N} \to \mathbb{N}}$ (the function that takes a natural
number and returns 0), by the above definition of the least element in the
$\omega$-cpo defined on a function space. By repeated application of $F$ the function
will slowly approach the real factorial function, which is the fixed point of $F$.
The beginning of the iteration will be

\begin{align*}
  F_1(n) = F(F_0(n)) & = \begin{cases}
                           1~~~\text{if }n\text{ is 0}\\
                           0~~~\text{otherwise}
                         \end{cases}
  \\
  F_2(n) = F(F(F_0(n))) & = \begin{cases}
                             1~~~\text{if }n\text{ is 0}\\
                             1~~~\text{if }n\text{ is 1}\\
                             0~~~\text{otherwise}
                           \end{cases}
  \\
  F_3(n) = F(F(F(F_0(n)))) & = \begin{cases}
                                1~~~\text{if }n\text{ is 0}\\
                                1~~~\text{if }n\text{ is 1}\\
                                2~~~\text{if }n\text{ is 2}\\
                                0~~~\text{otherwise}
                              \end{cases}
\end{align*}

In this case it is easy to see that $F_0 \leq F_1 \leq F_2 \leq F_3 \leq \dots$. In
the general case this follows from the fact that $F$ has to be monotone and $F_0$ is
always the least element of the function space $F$ operates on. 


\subsection{Interpreting probabilistic definitions}\label{sec:prob-interp}
In order to interpret probabilistic definitions, we need a way of expressing
the distribution of possible results. For this we will use probability measures as
described in \cite{rml-paper}.

\subsubsection{The concept of measures}
In layman's terms, we can describe a measure on a set $A$ as exactly that: a way of
measuring subsets of $A$. More precisely, a measure on $A$ assigns a non-negative
real number to every ``suitable'' subset of $A$, where ``suitable'' means fulfilling
certain conditions. We will henceforth write $\mu (X)$ to signify the value of $X
\subseteq A$ under the measure $\mu$.

In order for a function to be a measure, there are three properties it has to have:
It must take only non-negative values, $\mu (\varnothing) = 0$, and it has to be
countably additive. Being countably additive means that for every set of pairwise
disjoint objects, the value of this set is equal to the sum of the values of each
object:

\begin{equation*}
  \mu (X) = \mu(\bigcup_{x\in X} x) = \Sigma_{x\in X} \mu (x)
\end{equation*}

An example might be to choose $A$ to be a set of 3-dimensional objects and a possible
measure would be the total volume of objects in a subset. 

We can understand a measure on $A$ as integral
over functions from $A$ to $\mathbb{R}^+$. From this perspective, the above example
would consist of the function that given an object in $A$ returns its volume. The
integral over this function would be the volume of all objects in $A$. Now the
challenge is to measure only a subset of $A$. We can do this by introducing the
characteristic function of a subset $X$\cite{wiki-measure}:

$$\mathbb{I}_X(x)=
\begin{cases}
  1~~\text{if }x\in X\\
  0~~\text{otherwise}
\end{cases}$$

By multiplying the characteristic function for $X$ with the volume function on
objects in $A$, we get a new function, $f$, such that $\int f~d\mu = \mu(X)$. With
this in place, we will allow ourselves to be sloppy in our notation and write
$\mu(f)$ instead of $\int f~d\mu$.

It is easy to see that the integral perspective still satisfies all the requirements
that a function has to fulfil in order to be a measure, and the reader is invited to
check this for herself.\\
\\
Now why all this talk about measures? Wasn't it probabilistic programs we were
talking about?

The cool thing is, that being able to measure function whose co-domain is the real
numbers in the unit interval, $\tau\to[0,1]$, gives us a way of representing
probability distributions. A measure on type $\tau$ can be expressed with the type
$(\tau\to[0,1])\to[0,1]$. An interpretation of a probabilistic term whose type is
$\tau$ can now be understood as a measure on type $\tau$, or equivalently as a
transformation of a probability distribution.

Something of type $\tau\to[0,1]$ can be understood as the function that returns the
probability of its input being part of a specified set, or in other words, we can
understand it as a probability density function. We can view our programs as a
transformation of a distribution: If we input an initial distribution (this might
also just be the characteristic function of a single value), we will as output
receive the integral over the transformed distribution; with other words, we will
receive the probability distribution specifying the result of an actual
pseudorandomised run of our program producing a result within the input distribution.

As an example we might consider the value \texttt{flip}, which returns a uniform
distribution of \texttt{false} and \texttt{true}. If now we supply the measure
representation of this value with the characteristic function of \texttt{true}, the
result will be 0.5, since this is the probability of \texttt{true} being the
outcome.

But the function we measure is not constrained to being the characteristic function
of a finite set. We can use functions specifying infinite sets, or sets that contain
values with some probability. 
We could, for example, have a set that contains \texttt{true} with
probability $p$ and \texttt{false} with probability $q$.
The characteristic function of this set is
$$\mathbb{I}_X =
\begin{cases}
  \texttt{true} \mapsto p\\
  \texttt{false} \mapsto q
\end{cases}$$
 
In order to find out what the probability is of a uniformly random choice between
\texttt{true} and \texttt{false} being in this set, we apply the measure
representation of \texttt{flip} to $\mathbb{I}_X$. The result is the integral over
the joint probability distribution of \texttt{flip} and $\mathbb{I}_X$. 

\subsubsection{A monadic interpretation}
\label{sec:monad-interp}
We can represent measures using a monadic structure. This is sensible, since
probabilistic programs are inherently not functional and once probability is involved
in a computation we can not get rid of it again; this fits with a monad where we can
not get a value back out of the monad once it is in the monad, unless we work with
the representation of the monad in our language.

Since we are using a monad over the type $\tau$ to represent a measure on $\tau$, we
will for simplicity of notation introduce the notation \texttt{M}$\tau$ to mean 
$(\tau\to[0,1])\to[0,1]$.\\ 
\\
The monadic operators presented here have been formerly introduced by \cite{rml-paper}
and satisfy the usual monadic properties\footnote{There are many introduction to the
theory of monads. One example is our previous development in Coq, which can be found
at
\url{https://bitbucket.org/Ninijura/functionalprogramming/raw/47de0f3f259370f3214789bbc90511313be451f8/project/report_final.pdf}}. They
are also used by the Mathematical Components compliant Analysis Library\footnote
{\url{https://github.com/math-comp/analysis/tree/master/}} in their representation of
distributions.

\begin{align*}
  \texttt{unit} & :~ \tau\to\texttt{M}\tau\\
                & = \texttt{fun }(x:\tau)\Rightarrow
                  \texttt{fun }(f~:~\tau\to[0,1])\Rightarrow f~x\\
  \texttt{bind} & :~\texttt{M}\tau\to(\tau\to\texttt{M}\sigma)\to\texttt{M}\sigma\\
                & = \texttt{fun }(\mu~:~\texttt{M}\tau)\Rightarrow \texttt{fun }
                  (g~:~\tau\to\texttt{M}\sigma) \Rightarrow\\
                & ~~~~\texttt{fun }(f~:~\sigma\to[0,1])\Rightarrow \mu~ (\texttt{fun
                  }(x~:~\tau)\Rightarrow M~x~f)
\end{align*}
\\
These definitions look big and scary, so let's break them down.
\\ \\
The \texttt{unit} function could be described as the ``wrapper'' that takes a value
and wraps the monad around it. The outermost lambda-abstraction takes the value that
we want to produce the measure of and remembers it. The second function binding is to
match the type of measures; this is where the probability distribution is received as
input, and where we then give the output of said distribution function applied to our
initial value.

A simple example could be \texttt{unit 5} applied to the uniform distributions of
numbers between 1 and 5. The result would then be 0.2, since that is the probability
of a (pseudo-)random sampling from our measure (we recall that in this case it is
just the characteristic function $\mathbb{I}_{\{5\}}$) and a (psuedo-)random sampling
from the initial distribution coinciding. 
\\ \\
The \texttt{bind} function can be viewed as something transforming the value inside
the monad. 
Let us take it from the inside and out. Clearly the last line of the definition is
the result, the \texttt{M}$\sigma$ part; this is obvious from the types. $\mu$ and
$g$ are the usual arguments to a \texttt{bind} operation, $\mu$ being the initial
value and $g$ the transformation to be applied to it.

We can view the final construction like continuation passing style programming. We
still have a value of type $\tau$ inside the monad before we bind it into a function,
and we want to retain that information in the result of the \texttt{bind}. But we can
not access this information unless we supply the value of type \texttt{M}$\tau$ with
a function of type $\tau \to [0,1]$; this function is the one that $\mu$ is applied
to in the final value. Since the result is of type \texttt{M}$\sigma$, it would make
sense to use its input on something of type $\sigma$ to get something in [0,1], which
would satisfy the output type for the function we apply $\mu$ to.

The final function takes the input of type $\tau$, that $\mu$ will give it,
applies $g$ to it to transform it to something of type \texttt{M}$\sigma$, and then
supplies it with the last piece of the computation, $f$.

This way we retain all of the information that is contained in $\mu$, transform it
with $g$, and lastly transform it with $f$, once that is supplied.\\
\\
An example of the use of \texttt{bind} could be the following: We have a distribution
of natural numbers, $\mu$, and we want to figure out what the probability is that a
number drawn from this distribution is even. To this end, we use the function $g$,
that takes a natural number and returns the probability of it being even. If now we
apply the result of \texttt{bind $\mu$ $g$} to, let's say, the characteristic
function of \texttt{false}, the following computation will be carried out:

$\texttt{fun }(x~:~\tau)\Rightarrow g~x~f$ is now the function that takes a natural
number and returns the probability of it being odd. Applying $\mu$ to this function
yields the probability of a pseudorandom interpretation of $\mu$ being an odd
number; and this is exactly the meaning of

(\texttt{bind $\mu$ $g$}) (\texttt{fun
  ($x$ : bool) $\Rightarrow$ if $x$ then 0 else 1}).

\subsection{Putting together recursion and probability}
\label{sec:prob-rec}
What now if we want both probability and a way of interpreting general recursion?
Then we need the $\omega$-cpo structure on our functions even though they are wrapped
in an additional abstraction.

In order to show this, we use the fact that monotonic functions from an ordered set
to an $\omega$-cpo also have an $\omega$-cpo structure \cite[p.~584]{rml-paper}.
Because a probability measure is an integral over strictly non-negative functions, it
is a monotonic function. It is a function to [0,1], which clearly is an $\omega$-cpo
with zero-element being zero, the ordering relation being $\le$ as we know it for
real numbers, and the least upper bound operation simply being the largest number of
a monotonic sequence.

Now we have that a measure is a monotonic function to an $\omega$-cpo, which is
exactly what we needed to be sure of, before we go ahead and combine probability and
recursion. 


% Packages: comment
\subsection{The functional approach: \rml}\label{sec:rml}
The first language for probabilistic programs implemented in Coq is called \rml
('Randomised monadic language') and is due to is due toe Philippe Audebaud and
Christine Paulin-Mohring (\cite{rml-paper}).
\\ \\
\rml\ is a simple functional language whose interpretation allows for probabilistic
algorithms. The language itself does not contain probabilistic expressions, but
rather makes use of the functions \texttt{random($n$)} and \texttt{flip}, which give
a uniform distribution of natural numbers between 0 and $n$, and \texttt{true} and
\texttt{false}, respectively.

Since calling either function would be considered a valid \rml\ term, their semantics
is a distribution. Their typing is therefore:
\begin{align*}
  \texttt{random} &~:~\mathbb{N} \to \texttt{M }\mathbb{N}\\
  \texttt{flip}   &~:~ \_ \to \texttt{M }\mathbb{B}
\end{align*}
\noindent The expressions that our language consists of (we recall that it is a functional
language, so there are only expressions, no statements) are as follows:

\begin{align*}
  exp~::= ~ x~\vert ~ c~\vert ~ \texttt{if }b\texttt{ then }e_1\texttt{ else } e_2~
  \vert ~ \texttt{let }x = e_1 \texttt{ in }e_2~\vert ~ f~e_1~\dots~e_n
\end{align*}

Here $x$ refers to a variable name previously bound in a let-binding, and $c$ refers
to a primitive constant. Since Paulin-Mohring and Adebaud don't give a clear
definition of what a constant can be, it makes sense to assume, that it can be any
Coq term. This is beacuse their proposed approach to interpreting \rml\ in Coq is a
shallow embedding, which means that it uses Coqs type system and values instead of
defining its own. 

According to \cite{rml-paper}, the $f$ in function application can be a ``primitive
or a user-defined function'', where primitive would be \texttt{random($n$)} or
\texttt{flip}, and a user-defined function should be specified by \texttt{let
}$f~x_1~\dots~ x_n= e$, according to the language specification. Recursive functions
can be defined with the keyword \texttt{let rec}. Here, again, we could make use of
the fact that the paper proposes a shallow embedding and use Coq toplevel functions. 

The monadic interpretation $[e]:\texttt{M}\tau$ of a term $e:\tau$ is given in
Figure \ref{fig:rml-monad}.

\begin{figure}[h]
  \begin{center}
    \begin{tabular}{|c|c|}
      \hline
      \rml\ term $e~:~\tau$ & Interpretation $[e]~:~\texttt{M}\tau$\\
      \hline
      $v$ & \texttt{unit }$v ~~ v$ variable or constant\\ & \\
      $\texttt{let }x=a\texttt{ in } b$ & $\texttt{bind }[a]~(\texttt{fun } x
                                          \Rightarrow [b])$\\ & \\
      $f~a_1\dots a_n$ & $\texttt{bind }[a_1]~(\texttt{fun } x_1 \Rightarrow \dots
                         \texttt{bind }[a_n]~$ \\
                           & $(\texttt{fun } x_n \Rightarrow [f]~x_1
                             \dots x_n) \dots ) $\\ & \\
      \texttt{if $b$ then $a_1$ else $a_2$} &  $\texttt{bind } [b]~(\texttt{fun }
                                              x~:~\texttt{bool}) \Rightarrow$\\
                           & (\texttt{if $x$ then $[a_n]$ else $[a_2]$})\\
      \hline
    \end{tabular}\\
    \caption{Monadic interpretation of \rml\ terms as presented in \cite{rml-paper}.}
    \label{fig:rml-monad}
  \end{center}
\end{figure}

\subsection{\textsc{EasyCrypt} and \texttt{pwhile} (or 'The imperative approach')}\label{sec:pwhile}
% Here we should give a quick description of EasyCrypt and present pwhile
\textsc{EasyCrypt} is a framework that has been developed in order to help in the
construction of machine-checkable proofs about cryptographic constructions and
protocols \cite{easy-crypt}. For the implementation of algorithms, it makes use of a
simple imperative language called \texttt{pwhile}. The \texttt{p} in \texttt{pwhile}
stands for ``probabilistic'', so in total the name refers to a probabilistic
extension of the well-known minimalistic \texttt{while} language.

We will in this section give an overview of the language as well as its
interpretation in Coq, which is due to a development by Pierre-Yves Strub
\footnote{https://github.com/strub/xhl}. We will not concern ourselves with the
module system of \textsc{EasyCrypt} since the focus of the present development is
on probabilistic languages and their interpretation rather than their use.\\
\\
\texttt{pwhile} consists of the following expressions and commands: 
\begin{align*}
  exp ::=~& x ~\vert ~ const ~\vert ~ \texttt{prp ($p$ : pred mem)}~\vert ~ e_1\ e_2\\
  cmd ::=~& \texttt{abort} ~\vert ~ \texttt{skip} ~\vert ~ x := e ~\vert ~ x\ \$= e\\
  \vert ~ & \texttt{if } b \texttt{ then } c_1 \texttt{ else } c_2 ~\vert ~
            \texttt{while } b \texttt{ do } c ~\vert ~ c_1 ; c_2
\end{align*}

The embedding of \texttt{pwhile} in Coq is a so-called shallow embedding, which means
that we use Coq terms and types as part of programs in \texttt{pwhile}. This is used
in order to form expressions: Constants in \texttt{pwhile} are Coq constants, hence
an expression in \texttt{pwhile} can have any Coq type. In the implementation,
expressions are parameterised by their type.

Most of the above constructs are fairly standard and should be known to most
readers. In Figure \ref{fig:pwhile-sem} we give a full formal semantics of commands,
based on the monadic operations presented in Section \ref{sec:monad-interp}.

\begin{figure}[h]
  \begin{align*}
    \llbracket \texttt{abort} \rrbracket~m
    &~~= \texttt{dnull}\\
    \llbracket \texttt{skip} \rrbracket~m
    &~~= \texttt{unit }m\\
    \llbracket i;~c \rrbracket~m
    &~~= \texttt{bind }(\llbracket i \rrbracket~m) ~
      \llbracket c \rrbracket \\
    \llbracket x := e \rrbracket~m
    &~~= \texttt{unit }m [\llbracket e \rrbracket~m / x]\\
    \llbracket x~\$= d \rrbracket~m
    &~~= \texttt{bind } (\llbracket d \rrbracket~m) ~(\lambda v.\texttt{unit }m[v/x])
    \\ 
    \llbracket \texttt{if $e$ then $c_1$ else $c_2$} \rrbracket~m
    &~~= \begin{cases} \llbracket c_1 \rrbracket~m\text{ if} \llbracket e
           \rrbracket~m = \texttt{true}\\ 
           \llbracket c_2 \rrbracket~m\text{ if} \llbracket e \rrbracket~m =
           \texttt{false}\\ 
         \end{cases}\\
    \llbracket \texttt{while $e$ do $c$} \rrbracket~m
    &~~= \lambda f.\text{sup}~(\lambda n. \llbracket [\texttt{while $e$ do }c]_n
      \rrbracket)~ m~f)\\
    & ~~~~~~ \text{where}\\
    & ~~~~~~ [\texttt{while $e$ do }c]_0 ~~~ = \texttt{skip}\\
    & ~~~~~~ [\texttt{while $e$ do }c]_{n+1} = \texttt{if $e$ then $c$;} \\
    & \hspace{125pt}[\texttt{while $e$ do }c]_n
  \end{align*}
  \caption{Denotational semantics of \texttt{pwhile} programs based on the monadic
    structure presented in Section \ref{sec:monad-interp}. This interpretation is the
    same as presented in Chapter 2 of \cite{zanella}.}
  \label{fig:pwhile-sem}
\end{figure}


In addition to the standard expressions and commands, \texttt{pwhile} has the
expression \texttt{prp $p$}, which we will have a look at here.
\texttt{prp} takes a single argument of type \texttt{pred mem}. This is a Coq type
specified with the type constructor \texttt{pred} = $\forall \tau~:~\tau \to
\mathbb{B}$ applied to the type of memories defined in the \texttt{xhl}
development. The predicate over memories that is \texttt{prp}s argument is mapped
over the working memory at the time of evaluation.

For more clarity, we will look at an example. Let us take the situation where we only
want to proceed with a computation, if a certain variable, $x$ is defined in the
memory; we want to access $x$, but want to avoid our program crashing if $x$ has not
been defined. We now write the function \texttt{x\_defined} that, given a memory,
returns true if $x$ is defined in said memory and false otherwise. By branching on
\texttt{prp x\_defined}, we can now make sure that we only take the branch accessing
$x$ if it is present in the memory and do not end up with a program that may
crash. \\
\\
At this point a comment about ``crashing'' programs is in order. There are multiple
ways in which a program can lead to an undefined result: encountering undefined
behaviour, non-termination, and the \texttt{abort} command. The interpretation of all
of these is the same: We recall that the result of interpreting a \texttt{pwhile}
program in Coq is a probability distribution over memories; now the result of
interpreting a ``crash'' is by simply returning the null-distribution over memories.


\section{Equivalence of \rml\ and \texttt{pwhile} (READY)}\label{sec:approach}
% Goal: 6-12 pages

% Describe the translation from while to functional (+recursion), to lambda-calculus,
% to an interpretation in omega-cpos.

% We planned on making an interpretation of Rml in Coq and then translating the xhl
% implementation of pwhile to our abstract syntax. 

The goal of the present project was to gain an actionable understanding of \rml\ and
\texttt{pwhile}, their respective interpretations, theoretic background, and
similarities and differences between them. Our approach was to define a translation
between \texttt{pwhile} and \rml\ as well as an interpretation of \rml, and
subsequently show that translating from \texttt{pwhile} to \rml\ and interpreting the
resulting program would lead to the same interpretation as interpreting the
\texttt{pwhile} program directly.

This approach allowed us to get acquainted with both languages as well as the
difficulties in interpretation that both of them share.

\begin{figure}[h]
  \centering
  \begin{tikzcd}
    \texttt{pwhile} \arrow[rr] \arrow[d] &  & \omega\text{-cpos} \\
    \text{\rml} \arrow[rru]              &  &                   
  \end{tikzcd}
  \caption{The languages we work with and the direction of the translations between
    them. }
  \label{fig:triangle}
\end{figure}

In this section we will concern ourselves with the translation between
\texttt{pwhile} and \rml, as well as their respective interpretations. Throughout
this section we will disregard all typing rules. Adding types to the expressions
should not influence the semantics of the translations we present and is
straightforward. 

For the translations, we will first have a look at deterministic versions of both in
order to define the main part of the translations (Sections \ref{sec:while-to-fun},
\ref{sec:fun-to-lambda}). This means in order to show that the diagram of Figure
\ref{fig:triangle} commutes, we will first show that the following diagram commutes
(Section \ref{sec:lambda-interp}):

\begin{figure}[h]
  \centering
  \begin{tikzcd}
    \texttt{while} \arrow[rrr] \arrow[rd] & & & \omega\text{-cpos} \\
    & \text{fun}_{\texttt{Fix}} \arrow[r] & \lambda_\texttt{Y} \arrow[ru] &                   
  \end{tikzcd}
  \caption{A deterministic version of Figure \ref{fig:triangle} with an extra step
    added. }
  \label{fig:triangle-det}
\end{figure}
  
To round off the theoretic part, we will have a look at how to add probabilistic
constructs to all languages we use (Section \ref{sec:probab}).

We will briefly discuss how we would go about implementing the theory developed in
the current section in Coq (Section \ref{sec:howto-coq}), before we move on to
discussion our own Coq development in the following Section (Section
\ref{sec:contrib}).


\subsection{Translating \texttt{while} to a functional
  language}\label{sec:while-to-fun} 
% 
In order to do the translations properly, let us first have a look at a translation
from the simple, widely known \texttt{while} language to a simple functional language
resembling \rml. The thought behind this is that once this translation is in place,
all we have to do to translate \texttt{pwhile} to \rml\ is to add probability.
\begin{align*}
  exp~  ::=~~ & x \vert n \vert \texttt{true} \vert \texttt{false} \vert f~x \\
  stm~  ::=~~ & \texttt{skip} \vert x := e
               \vert \texttt{if } e \texttt{ then } s_1 \texttt{ else } s_2
               \vert \texttt{while } e \texttt{ do } s \vert s_1;s_2
\end{align*}

The syntax of our functional language is the same as \rml\ modulo the pre-defined
probabilistic functions and our repeating it here is solely for the reader's
convenience, not in order to introduce anything new. 
\begin{align*}
  exp~::= ~ x~\vert ~ c~\vert ~ \texttt{if }b\texttt{ then }e_1\texttt{ else } e_2~
  \vert ~ \texttt{let }x = e_1 \texttt{ in }e_2~\vert ~ f~e_1~\dots~e_n
\end{align*}


The translation of expressions is completely straightforward: variables are mapped to
variables, constants to constants, and function applications to function
applications.

In order to translate statements we choose a set of SML-style matching rules; this
choice is due to the translation of sequences being dependent on what the first
statement is. We will in the following write the translation of a \texttt{while}
statement $s$ to an expression in our functional language as $\llbracket s
\rrbracket$. 

The result of a computation in \texttt{while} is the state of a memory, while the
result of a functional computation is a value. A simple way to make up for this
difference is by choosing a variable name that is designated the return variable and
encapsulates the information we are interested in after the computation. This is the
result of a program translated from \texttt{while} to our functional language; in the
following we choose $x_r$ as the symbol for the chosen return variable. 
\begin{align}
  \texttt{skip}~;~s ~\mapsto~ & \llbracket s \rrbracket
\end{align}
\begin{align}
  \texttt{skip}     ~\mapsto~ & x_r
\end{align}
\begin{align}
  x := e~;~s        ~\mapsto~ & \texttt{let } x := e \texttt{ in }\llbracket s \rrbracket
\end{align}
\begin{align}
  x_r := e          ~\mapsto~ & e 
\end{align}
\begin{align}
  x := e            ~\mapsto~ & x_r
\end{align}
\begin{align}
  (\texttt{if } e \texttt{ then } s_1 \texttt{ else } s_2) ~;~s_3
                    ~\mapsto~ & \texttt{if } e \\
                    &  \texttt{ then } \llbracket s_1 ~;~ s_3 \rrbracket\notag\\
                    & \texttt{ else } \llbracket s_2 ~;~ s_3 \rrbracket \notag
\end{align}
\begin{align}
  \texttt{if } e \texttt{ then } s_1 \texttt{ else } s_2
                    ~\mapsto~ & \texttt{if } e
                                  \texttt{ then } \llbracket s_1 \rrbracket
                                  \texttt{ else } \llbracket s_2 \rrbracket 
\end{align}
\begin{align}
  (\texttt{while } e \texttt{ do } s_1) ~;~ s_2
                    ~\mapsto~ & \texttt{let rec } f~x :=
                                  \texttt{if } e \label{eq:while1}\\
                    & \phantom{{}=11111111111} \texttt{ then } \llbracket s_1 ~;~ f~x \rrbracket \notag\\
                    &\phantom{{}=11111111111}\texttt{ else } \llbracket s_2 \rrbracket\notag\\
                    & \texttt{ in } f~0 \notag 
\end{align}
\begin{align}
  \texttt{while } e \texttt{ do } s_1
                    ~\mapsto~ & \texttt{let rec } f~x :=
                                 \texttt{if } e \label{eq:while2}\\
                    & \phantom{{}=11111111111}\texttt{ then } \llbracket s_1 ~;~ f~x \rrbracket\notag\\
                    & \phantom{{}=11111111111}\texttt{ else } x_r \notag\\
                    & \texttt{ in } f~0\notag
\end{align}

Note that in \ref{eq:while1} and \ref{eq:while2} we create recursive functions with a
name and an argument, both of which are not present in the while construct we
translate from. This means that we have to be careful about the translation: Both $f$
and $x$ have to be chosen fresh; and even fresher than that, they can not occur in
the body of the while loop we are translating either, because that would break the
recursive call.

Further notice that the recursive functions are always called with a dummy
argument. This is because they act as procedures, but since our syntax requires an
argument for recursive definitions, we give a dummy argument.


\subsection{Towards the $\mathbf{\lambda}$-calculus}\label{sec:fun-to-lambda}  

In order to make the interpretation of programs easier for ourselves, we decided to
take an extra step in between the functional language and its interpretation: We use
the lambda calculus with the \texttt{Y}-combinator.

The translation is straightforward in most cases, the only thing that is a bit tricky
is the translation of recursive let-bindings. This is because the
\texttt{Y}-combinator may look confusing at first, but when we take a closer look at
it, we realise that it looks a lot like the fixed point iteration we presented in
Section \ref{sec:fixp-iter}.

\begin{align}
  \label{fig:fun-to-lambda}
  \llbracket x \rrbracket~\mapsto~
  & x\\
  \llbracket c\rrbracket~\mapsto~
  & c\\
  \llbracket\texttt{let }x := e_1\texttt{ in }e_2 \rrbracket~\mapsto~
  & (\lambda x.\llbracket e_2\rrbracket)~\llbracket e_1\rrbracket \\
  \llbracket \texttt{if $b$ then $e_1$ else }e_2 \rrbracket~\mapsto~
  &\texttt{if } \llbracket b\rrbracket \texttt{ then }\llbracket e_1\rrbracket
    \texttt{ else }\llbracket e_2\rrbracket \label{eq:lambda-if}\\
 \llbracket f~e_1\dots e_n \rrbracket~\mapsto~
  & \llbracket f\rrbracket~\llbracket e_1\rrbracket \dots \llbracket e_n\rrbracket\\
  \llbracket \texttt{let rec }f~x:= e_1 \texttt{ in } e_2\rrbracket ~\mapsto~
  & (\lambda f.\llbracket e_2\rrbracket)~(\texttt{Y}~
    (\lambda f.\lambda x. \llbracket e_1\rrbracket))
\end{align}

For simplicity, we decided to use a typed $\lambda$-calculus with the type of
booleans and an if-primitive, which we use in \ref{eq:lambda-if}.\\
\\
Now for the \texttt{Y}-combinator: It is a so-called \emph{fixed-point combinator},
this means it is a lambda-expression without any free variables which we can use to
find the fixed point of the application of a recursive definition. The expansion of
using the \texttt{Y}-combinator is, as mentioned before, substantially similar to the
fixed-point iteration we presented, so we will not discuss it in detail here but
refer any interested reader to \cite{y-combinator}. 

$\beta$-reduction of function application in the $\lambda$-calculus is to insert the
bound value instead of its identifier everywhere in the expression. In Sections
\ref{sec:rmlx} and \ref{sec:srml}, we will use this fact in order to rewrite \rml\
expressions into something that is easier for us to interpret. 

\subsection{Interpreting it both ways}\label{sec:lambda-interp} 
Finally, after having defined the translations, we would like to look at the
interpretations of both the $\lambda$-calculus and \texttt{while} and see that the
triangle shown in Figure \ref{fig:triangle-det} actually commutes.

To this end we will look at all the statements we have looked at for the translation
from \texttt{while} to a functional language, and compare their direct interpretation
with the interpretation of their translations to the $\lambda$-calculus. 

We prove that the triangle commutes by induction. The base cases are the expressions;
since these are the same in all languages and evaluated in the same way, they are
trivially true.

For the proof we will allow ourselves to be sloppy with environments and instead of
looking up variables simply replace occurrences of variable $x$ in statement $s$ by
the value of $x$ before interpreting $s$.

Our induction hypothesis is that the interpretation of any sub-term is equivalent for
direct interpretation (which we will write as $\mapsto^{\texttt{w}}$) and translation
to $\lambda$-calculus (which we will write as $\mapsto^\lambda$) with subsequent
interpretation. 

\begin{align}
  \texttt{skip} ~;~s ~\mapsto^{\texttt{w}}~ & \llbracket s \rrbracket\\
  \texttt{skip} ~;~s ~\mapsto^\lambda~ & \llbracket s \rrbracket\notag
\end{align}
\begin{align}
  \texttt{skip}     ~\mapsto^{\texttt{w}}~ & x_r\\
  \texttt{skip}     ~\mapsto^\lambda~ & x_r\notag
\end{align}
\begin{align}
  x := e~;~s        ~\mapsto^{\texttt{w}}~ & \llbracket s\rrbracket[e / x]\notag\\
  x := e~;~s        ~\mapsto^\lambda~ & (\lambda x.\llbracket s \rrbracket)~e
\end{align}
\begin{align}
  x_r := e          ~\mapsto^{\texttt{w}}~ & e \\
  x_r := e          ~\mapsto^\lambda~ & e \notag
\end{align}
\begin{align}
  x := e            ~\mapsto^{\texttt{w}}~ & x_r \\
  x := e            ~\mapsto^\lambda~ & x_r \notag
\end{align}
\begin{align}
  (\texttt{if } e \texttt{ then } s_1 \texttt{ else } s_2) ~;~s_3
                    ~\mapsto^{\texttt{w}}~ & \texttt{if } e \\
                    &  \texttt{then } \llbracket s_1 ~;~ s_3 \rrbracket\notag\\
                    & \texttt{else } \llbracket s_2 ~;~ s_3 \rrbracket \notag\\
  (\texttt{if } e \texttt{ then } s_1 \texttt{ else } s_2) ~;~s_3
                    ~\mapsto^\lambda~ &  \texttt{if } e \\
                    &  \texttt{then } \llbracket s_1 ~;~ s_3 \rrbracket\notag\\
                    & \texttt{else } \llbracket s_2 ~;~ s_3 \rrbracket \notag
\end{align}
\begin{align}
  \texttt{if } e \texttt{ then } s_1 \texttt{ else } s_2
                    ~\mapsto^{\texttt{w}}~ & \texttt{if } e
                                  \texttt{ then } \llbracket s_1 \rrbracket
                                  \texttt{ else } \llbracket s_2 \rrbracket \\
  \texttt{if } e \texttt{ then } s_1 \texttt{ else } s_2
                    ~\mapsto^\lambda~ & \texttt{if } e
                                  \texttt{ then } \llbracket s_1 \rrbracket
                                  \texttt{ else } \llbracket s_2 \rrbracket \notag
\end{align}
\begin{align}
  (\texttt{while } e \texttt{ do } s_1) ~;~ s_2
  ~\mapsto^{\texttt{w}}~ & sup_n(\llbracket \texttt{unfold-while-n-times }e~s_1
                \rrbracket) ~;~\llbracket s_2\rrbracket \label{eq:while-sec-both}\\
  (\texttt{while } e \texttt{ do } s_1) ~;~ s_2
  ~\mapsto^\lambda~ & (\lambda f. f~0)\notag\\
                         &(\texttt{Y }(\lambda f.\lambda x.(e~(\llbracket
                           s_1~;~f~x\rrbracket) ~(\llbracket s_2\rrbracket )))\notag
\end{align}
\begin{align}
  \texttt{while } e \texttt{ do } s_1
  ~\mapsto^{\texttt{w}}~ & sup_n(\llbracket \texttt{unfold-while-n-times }e~s_1
                           \rrbracket)\label{eq:while-both} \\
  \texttt{while } e \texttt{ do } s_1
  ~\mapsto^\lambda~ & (\lambda f. f~0)\notag\\
                         &(\texttt{Y }(\lambda f.\lambda x.(e~(\llbracket
                           s_1~;~f~x\rrbracket) ~(x_r)))\notag
\end{align}
Most of the cases follow directly from the induction hypothesis, the base cases, or
$\beta$-reduction of the $\lambda$-term in combination with the base cases and the
induction hypothesis. We will leave it to the reader to convince himself of this.

The interesting cases are those with a looping construct, so let us have a look at
those.\\
\\
For the interpretation of \texttt{while}, we introduced two new constructs in the
meta language: $sup_n$ and \texttt{unfold-while-n-times}.

The first one is obvious after reading Section \ref{sec:fixp-iter}: $sup_n$ takes a
monotonic sequence (so a monotonic function of the natural numbers) and finds its
supremum.

\texttt{unfold-while-n-times} does exactly what its name says. It takes a loop
condition, $e$, a loop body, $s_1$, and a numeric argument, $n$, and computes
$\underbrace{\texttt{if $e$ then $s_1$ else skip ; $\dots$ ; if $e$ then $s_1$ else
    skip}}_{n\text{ times}}$. It is worth noting, that this way of unfolding the loop
saves us the trouble of introducing an environment for the interpretation. Since we
assumed the environment to be properly updated after each statement, and all we do is
produce a number of subsequent statements, this lies implicitly in the calculation. 

The supremum of this sequence is the result of the \texttt{while} loop after it has
terminated, or undefined if it does not terminate. It may not seem to the reader as
if this sequence of unfolding \texttt{while} a number of times is monotonic, since
the result may change both up and down, but this is not what we consider when we talk
of a monotonic sequence in this case. The sequence is monotonic in how defined it
is. When it is fully defined, the result will stay the same, no matter how many more
times we unfold, since at that point the looping condition will be false in the
environment. Because of this, we can also talk about the supremum as the fixed point
of the \texttt{while}-loop.\\
\\
So far so good, now what about the equivalence with the $\lambda$-term?
For convenience let us first argue about the case of \ref{eq:while-both} and
afterwards we will see that case \ref{eq:while-sec-both} follows with ease.

We know that \texttt{Y} $f$ evaluates to $f$ (\texttt{Y} $f$), for simplicity's sake,
we will, without loss of generality, assume that the evaluation is lazy; this means
that we can take steps evaluating the recursion.

Let us look at the evaluation of the full term.
$$(\lambda f. f~0) (\texttt{Y }(\lambda f.\lambda x.(e~(\llbracket
s_1~;~f~x\rrbracket) ~(x_r)))$$ 
$$\equiv_\beta$$
$$(\texttt{Y }(\lambda f.\lambda x.(e~(\llbracket s_1~;~f~x\rrbracket) ~(x_r))))~ 0 $$
$$\equiv_\beta$$
$$(\lambda f.\lambda x.(e~(\llbracket s_1~;~f~x\rrbracket) ~(x_r)))~(\texttt{Y
}(\lambda f.\lambda x.(e~(\llbracket s_1~;~f~x\rrbracket) ~(x_r))))~ 0 $$ 
$$\equiv_\beta$$
$$e~(\llbracket s_1~;~(\texttt{Y }(\lambda f.\lambda x.(e~(\llbracket
s_1~;~f~x\rrbracket) ~(x_r))))~0 \rrbracket) ~x_r $$

At this point we notice, that we now have the exact same construct as unfolding the
\texttt{while}-loop once: If $e$ is evaluated to \texttt{true}, we will keep
unfolding until we reach the fixed point of the function that the
\texttt{Y}-combinator is applied to. If the function diverges, the fixed point is
undefined, which is the same result that we get when we evaluate a diverging
\texttt{while}-loop.

If the sequence converges, we end up evaluating $s_1$ as many times as is necessary
for $e$ to be evaluated to \texttt{false} (just as we did in the direct
interpretation), and afterwards we return $x_r$. We note that $x_r$ is the return
variable for any \texttt{while} program in our setting, so this is the same as the
direct interpretation of \texttt{skip}. So in principle we have found the supremum of
unfolding \texttt{while $e$ do $s_1$ ; skip}, which is equivalent to the direct
evaluation of \ref{eq:while-both}.

The last step is to argue that this still works if the \texttt{while}-loop is the
first statement in a sequence. When translating this, we will end up with 
$$e~(\llbracket s_1~;~(\texttt{Y }(\lambda f.\lambda x.(e~(\llbracket
s_1~;~f~x\rrbracket) ~(x_r))))~0 \rrbracket) ~s_2 $$
Since we know that if the construct does not diverge, we will arrive at this
expression at a point where $e$ evaluates to \texttt{false}, so we will take the
$s_2$ branch. This is the same as interpreting \texttt{if $e$ then $s_1$ else skip ;
  $s_2$} where we know that $e$ evaluates to false. This is exactly the statement we
will end up with after unfolding the \texttt{while}-loop often enough to arrive at
its fixed point in the direct interpretation. The rest follows from the induction
hypothesis. 


\subsection{Adding probabilistic definitions}\label{sec:probab}
After having looked at the skeleton of the translations, now we want to make sure
that it all still works when adding probabilistic functions. To this end we use the
monadic structure  presented in Section \ref{sec:monad-interp} as the space to
interpret in.

We have already seen a monadic interpretation of \rml\ in Figure \ref{fig:rml-monad}
and one of \texttt{pwhile} in Figure \ref{fig:pwhile-sem}. Adding an interpretation
like this for the $\lambda$-calculus would be the first step from proving that the
diagram in Figure \ref{fig:triangle-det} commutes to proving that the diagram for the
non-deterministic languages in Figure \ref{fig:triangle} commutes.

We would then have to repeat the proof of Section \ref{sec:lambda-interp} with the
interpretation in said monadic structure instead of the proposed straightforward
interpretation.

An important part of this proof is that, since we want to interpret into the space of
$\omega$-cpos, we have to make sure that the space of our interpretation is actually
an $\omega$-cpo. Here we recall Section \ref{sec:prob-rec}, in which we argue that
the monad we presented in Section \ref{sec:monad-interp} has an $\omega$-cpo
structure to it. We use this structure in order to interpret recursive definitions
and looping constructs. 

Lastly we note that the probabilistic computations for both \rml\ and \texttt{pwhile}
are fully contained in the probabilistic functions \texttt{flip} and \texttt{random
  $n$}. This makes it easy to add probabilistic computations to the languages without
changing the translations between them, since using probability boils down to
applying a predefined function that is the same for all languages. 

\subsection{Implementing the translations in Coq}
\label{sec:howto-coq}
We tried implementing the approach of this Section in Coq, but it turns out that we
were not skilled enough in the use of Coq in order to implement all of the
translations of this section in the time given. What we have implemented is a
translation from \rml\ to \srml --a language of our own making that bears resemblance
to the $\lambda$-calculus--and its interpretation using the $\omega$-cpo structure on
the probability monad. 

In order to implement the rest of the translations, we would use the \texttt{xhl}
development for a Coq implementation of \texttt{pwhile}. We would then define the
translation to \rml\ according to what we presented in Section
\ref{sec:while-to-fun}, and then prove that for all well-formed
\texttt{pwhile}-programs, $p$, evaluating $p$ using the semantics implemented in
\texttt{xhl} leads to the same value as translating $p$ to \rml\ and interpreting the
result using our implementation. 

% \todo[inline]{Hey Bas, is this section really as easy as I think it is? It's pretty
%   much just saying that instead of interpreting things directly in our meta-language,
%   we add the monadic structure in between, make everything a probability distribution
%   instead of a decisive value, and add some probabilistic function definitions,
%   right? }

% \todo[inline, color=green!40]{We now interpret in another space (the monad, y'know),
%   so we have to argue that all we did before still works. This is where the argument
%   that the monad has w-cpo structure becomes important. Make sure you explain very
%   well what the issues are with adding probabiliyt. Specifiy the exact tasks we'd
%   have to do to implement the whole thing.}


\section{The Coq development (READY)}\label{sec:contrib}
% Goal: 6-12 pages
The proof of the previous section concerns itself with languages that are designed
for an implementation in Coq. So what would make more sense than implementing the
proof in Coq?

We did not implement the full proof of Section \ref{sec:approach}; our development
contains an implementation of a language based on \rml, a number of definitions
concerning the correctness of programs in said language, as well as an interpreter
for such correct programs. Our goal was to implement \rml\ according to its
specification, but due to a number of wrestling matches with Coq's typechecker, we
ended up deviating from what was presented in \cite{rml-paper}.

We will in the following call the language we actually implemented \rmlx, while we
will continue to call the original specification given in \cite{rml-paper} \rml. 

\subsection{The definition of \rmlx}
\label{sec:rmlx}

In order to write an interpreter for a language, we need to have a way to represent
the language's abstract syntax. To this end we define a datatype using the Coq
keyword \coqe{Inductive}. 

\begin{figure}[h]
  \centering
  \begin{minipage}{0.8\linewidth}
    \begin{lstlisting}[language=coq]
Inductive Rml :=
| Var : (nat * Type) -> bool -> Rml 
| Const : forall {A : Type}, A -> Rml
| Let_stm : (nat * Type) -> Rml -> Rml -> Rml
| If_stm : Rml -> Rml -> Rml -> Rml
| App_stm : Type -> Rml -> Rml -> Rml
| Let_rec : Type -> Type -> nat -> nat -> Rml -> Rml -> Rml
| Random : Rml -> Rml
| Flip : Rml.
    \end{lstlisting}
  \end{minipage}
  \caption{The inductive definition or \rmlx\ abstract syntax.}
  \label{fig:rmlx}
\end{figure}


The names of the constructors are straightforward and easily recognised from the
discussion of \rml\ in Section \ref{sec:rml}. The arguments that each constructor
takes are specific to our implementation so let us have a look at them.

\paragraph{\coqe{Var}} takes a pair of a natural number and a type as well as a boolean. 
The number and the type represent the information to identify a variable with. We use
natural numbers as identifiers because they are easy to work with, and the only
requirement for an identifier is that there is an equality operation on its type. The
second part of the pair is the type of the variable. The type information of a
variable is needed for type-checking and interpretation of an expression, because it
enables us to check that the value of said variable has the type we expect it to
have.

The second argument for the construction of a variable is a boolean value. This is
used to indicate if the variable refers to something bound by a previous let binding,
otherwise it is something we need for type-checking the function body of a recursive
definition. We will go into more detail about how this is used in Section \ref{sec:srml}.

\paragraph{\coqe{Const}} constructs a constant and is straightforward. The only explicit
argument it takes is a Coq value; the implicit argument \texttt{A} is the type of
said value.

At this point it should be noted, that in Coq functions are values as well, so it is
possible to have a constant whose type is a function type. In other words: When we
want to access a Coq-toplevel function in our \rmlx\ program, we can do this by
encapsulating it in an \rmlx\ constant. 

\paragraph{\coqe{Let_stm}} is rather straightforward. The pair of a natural number and a
type is the identifier of the variable being defined. The first argument of type
\coqe{Rml} is the value of the variable, and the other is the expression the value is
being used in.

For example \coqe{Let_stm (x,T) $e_1$ $e_2$} would, in \rml\ syntax, be written as
\texttt{Let (x:T) := $e_1$ in $e_2$}. 

\paragraph{\coqe{If_stm}} is straightforward. All this constructor takes are the condition
and the two branches, all in form of \coqe{Rml} values.

\paragraph{\coqe{App_stm}} takes an argument more or one less than we would
intuitively expect. It takes one type as argument instead of either inferring the
types or asking for both the function type and the result type.

The trick here is that when type-checking, we know the type we expect the whole application
expression to have, but we do not know what to expect from the function or its
argument. We therefore explicitly supply the intermediate type. 

An example would be \coqe{App_stm nat~ (Const is_even) (Const 50)}, where we would
typecheck the whole expression to have type \coqe{bool}, while we need the explicit
\coqe{nat} to check that the argument has the right type for the function.

\paragraph{\coqe{Let_rec}} is the most complicated of the linguistic constructs of
\rmlx. It takes two types, two identifiers (natural numbers) and two \coqe{Rml}
expressions.

The two types are rather straightforwardly the domain and co-domain of the
recursively defined function.

The identifiers are the name of the function and the name of its argument,
respectively. Both can be referred to in the function body, which is the first
argument of type \coqe{Rml}.

The last argument should be an \coqe{Rml} value of the same type as the newly defined
function's argument. This is probably our largest deviation from the original
specification of \rml. We do not have any expressions of the form \texttt{Let rec
  \dots in \dots}, instead we require to be recursive definitions to be of the form
\texttt{Let rec f x := \dots in f(\dots)}. This way of writing and using recursive
functions has the exact same expressiveness as the common form, but it is easier to
interpret in Coq.

Note that this way of defining \texttt{Let rec}s removes the necessity of having a
function environment. Each function is used right where it is defined and can not be
called in the rest of the program, so effectively there is no binding of anything
happening in our so-called \coqe{Let_rec}. 

\paragraph{\coqe{Flip} and \coqe{Random}} are the two probabilistic functions
mentioned in Section \ref{sec:rml}. We added these to our abstract syntax, since this
makes it easier for us to interpret them as \coqe{Rml} terms instead of just as
distributions. Effectively the types are the same, but having them as part of our
abstract syntax makes them more readily accessible in \rmlx\ programs. \\
\\
It is easy to see that all of the additional information we store in our abstract
syntax tree is something that a parser would be able to infer and add. It would even
be possible to transform the shape of a recursive let-binding at parse-time so it
would fit our abstract syntax. This might introduce more recursive let-bindings, if
the function is used in multiple places in the original code, but apart from this,
the result would be equivalent. 


\subsection{Baby steps: The advent of \srml}
\label{sec:srml}
In our first try to interpret \rml\ directly, we were not able to figure out how to
use environments for the interpretation of let-bindings in a way that Coq would
accept. So instead of going from \rml\ directly to its interpretation (as was
suggested in \cite{rml-paper})
we took a step in between. We defined a language of simplified \rml, \srml. The main
difference between \rml\ and \srml\ is that \srml\ does not have let-bindings; there is,
however, still a construct that is the same as the previous \coqe{Let_rec} which we
call \coqe{sFix}, but as mentioned earlier, this construction does not actually bind
anything to an identifier, so there is no problem with environments here.

\begin{figure}[h]
  \centering
  \begin{minipage}{0.8\linewidth}
    \begin{lstlisting}[language=coq]
      Inductive sRml {A : Type} :=
      | sVar : nat -> sRml
      | sConst : A -> sRml
      | sIf : @@sRml bool -> sRml -> sRml -> sRml
      | sApp : forall T, @@sRml (T -> A) -> @@sRml T -> sRml
      | sFix : forall B (nf nx : nat), @@sRml A -> @@sRml B -> sRml
      | sRandom : (A = nat) -> @@sRml nat -> sRml
      | sFlip : (A = bool) -> sRml.
    \end{lstlisting}
  \caption{The inductive definition or \srml\ abstract syntax.}
  \end{minipage}
\end{figure}

Having this definition in place, the next step is to translate \rmlx\ to \srml. This
is done by the function \coqe{replace_all_variables_type}, which can be found in
Appendix \ref{app:rml-to-srml}. 

We replace the variables by traversing our abstract syntax tree and building an
environment that contains the identifier, type, and value of each variable that is
bound. As we go, we construct the abstract syntax of an \srml\ expression. Most of
the cases are straightforward and an \rmlx\ construct is just replaced with the
corresponding \srml\ construct. The interesting cases are \coqe{Var} and
\coqe{Let}.

\paragraph{Variables} refer to let-bindings, so we want to get rid of them. But we
still want to be able to have recursive function definitions, so we can not get rid
of the variables that are the function name and argument in a recursive
definition. This means we need a way to distinguish them. Here the extra boolean
argument that the constructor \coqe{Var} takes comes into play:
\begin{itemize}
    \item If it is \texttt{false}, we look up the variable in the environment and
  replace it with its value.
    \item If it is \texttt{true}, we know that we are currently looking at the body
  of a recursive definition and have no value with which to replace the variable, so
  we construct an \coqe{sVar} for it. 
\end{itemize}

\paragraph{Let-bindings} are what we want to get rid of in our simplification. We
just saw how we get rid of variables referring back to bindings, so now for the
actual binding part.

When we encounter a let-binding in our translation, we have to make sure that we can
replace all variables in its body with their value by just looking into the
environment. This means that we have to extend the environment with the newly bound
variable and then replace all the variables in its body. And this is exactly what we
do. We call the function to replace variables recursively, on the body of the
let-binding with the newly extended environment. 


\subsection{Typing \rmlx}
But how can we be sure that the translation from \rmlx\ to \srml\ actually works and
does not ``go wrong''? 
Having learned from Robin Milner \cite{milner}
we know that in order to ensure this we must implement some typing rules and a way to
check that a program is well-typed.

Before we commence the discussion of what it means for \rmlx\ or \srml\ expressions
to be well-typed, we should mention that we decided on using the axiom of decidable
equality for types. We could alternatively have defined an even deeper embedding of
\rml\ in Coq by defining a datastructure for \rml -types instead of using
Coq-types. This, however, would not have changed our outcome, so we decided against
the additional work.

The rules we implemented are straightforward and can be found in Appendix
\ref{appendix:rmltypes}. 

The attentive reader will have noticed that \srml\ is parameterised by a type
representing the type of the constructed expression. This is in order to help us (and
Coq) during the interpretation. The required types are consistent with the specified
typing rules and are added during the translation from \rmlx\ to \srml. 
This means that in order to translate, the \rmlx\ expression we are trying to
translate has to be well-typed; we assure this by our taking as argument a proof of
the well-typedness of the expression to be translated.

The output of our translation is of type \coqe{forall (A : Type), verified_srml A nil},
whose definition can be seen in Figure~\ref{fig:verified-srml}. This means that the
output of our translation effectively is a pair of the resulting \srml\ expression
and a proof of its well-typedness. This, again, is to help us through the actual
interpretation. 

\begin{figure}[h]
  \centering
\begin{lstlisting}[language=coq]
  Inductive verified_srml (A : Type) (fl : seq (nat * Type)) : Type :=
      verified : forall y : sRml, srml_valid_type A fl y -> verified_srml A fl
\end{lstlisting}
  \caption{The inductive definition of the type \coqe{verified_srml}.}
  \label{fig:verified-srml}
\end{figure}

When defining the translation from \rmlx\ to \srml, we had to define a few helping
lemmas along the way, in order to be able to prove everything correct. The most
important one of these is weakening, which we had to prove for both the variable
environment and the function environment for \rmlx\ as well as for the function
environment for \srml.

Weakening means that even though we extend our environment (with a let-binding), the
interpretation of the expression is still well-typed.
We had a tiny problem along the way here: What if we bind a new variable with the
same name but of a different type? Then the expression inside the new let-binding
might be ill-typed.

We fixed this by defining the lookup of a variable to not only refer to its name, but
also its type (cf. Figure \ref{fig:rmlx} and the subsequent discussion). This way we
can be sure that the variable we retrieve is of the right type.  


\subsection{But what does it mean? Interpreting \srml}
After all this talk about how we define well-typedness of \rmlx\ and \srml, we want
to finally make use of it.

Our interpretation of \srml\ is based heavily on the previously presented
interpretations for \texttt{pwhile} and \rml, and hence its result type is
\coqe{forall (A : Type), distr R (Choice A)}; or with other words: We interpret
\srml\ expressions of type $\tau$ as distributions over the type of $\tau$. This
should remind the careful reader of how we presented the interpretations of \rml\ and
\texttt{pwhile} in Sections \ref{sec:rml} and \ref{sec:pwhile}.

The additional elements of \coqe{R} and \coqe{Choice} are due to the implementation
of distributions in the Mathematical Components compliant Analysis Library that we
mentioned in Section \ref{sec:monad-interp}.

Since most of the set-up for the interpretations has been presented throughout
Section \ref{sec:theory}, we will here only present a formal version of the
semantics whose implementation can be found in the Coq definitions \coqe{ssem_aux}
and \coqe{ssem}. 

\begin{figure}[h]
  \begin{align*}
    \llbracket\texttt{sVar }n\rrbracket _{\texttt{env}}
      &=~~ \texttt{env}(n)\\ 
    \llbracket\texttt{sConst }a\rrbracket_{\texttt{env}}
      &=~~ \texttt{unit }a\\
    \llbracket\texttt{sIf }b~c_1~c_2\rrbracket_{\texttt{env}}
      &=~~ \texttt{bind }\llbracket b\rrbracket\texttt{env }(\lambda x.\texttt{if $x$}\\ 
      & \hspace{110pt}\texttt{then } \llbracket c_1\rrbracket_{\texttt{env}} \\
      & \hspace{110pt}\texttt{else } \llbracket c_2
        \rrbracket_{\texttt{env}})\\
    \llbracket\texttt{sApp }\tau~f~x\rrbracket_{\texttt{env}}
      &=~~ \texttt{bind }(\lambda t. \texttt{bind }(\lambda u. \texttt{unit }(t~u))\\
      & \hspace{100pt} \llbracket x \rrbracket_{\texttt{env}})\\
      & \hspace{52pt}\llbracket f \rrbracket_{\texttt{env}}\\ 
    \llbracket\texttt{sFix }\tau~f~x~e_1~e_2\rrbracket_{\texttt{env}}
      &=~~ \texttt{bind $($dlim }F^n)~ \llbracket e_2 \rrbracket _{\texttt{env}}\\
      & \hspace{22pt} \text{where}\\
      & \hspace{22pt}F^0 \hspace{11pt} ~=~ \texttt{dnull}\\
      & \hspace{22pt}F^{n+1} ~=~  (\lambda f'.\lambda x'. \llbracket e_1 \rrbracket
        _{\texttt{env}}[x'/x][f'/f])~F^n\\
    \llbracket\texttt{sRandom } e\rrbracket_{\texttt{env}}
      &=~~\texttt{bind }(\lambda x.\texttt{uniform $($range } x))
        ~\llbracket e \rrbracket _{\texttt{env}}\\
    \llbracket\texttt{sFlip }\rrbracket_{\texttt{env}}
      &=~~ \texttt{flip}
  \end{align*}
  \caption{Denotational semantics of \srml.}
  \label{fig:srml-sem}
\end{figure}

\texttt{uniform} and \texttt{flip} are functions defined by the \texttt{mathcomp}
library that return probabilistic distributions represented in the same way as we
represent them in our development.

\texttt{uniform} takes as input a list and outputs a uniform distribution over the
elements in this list. Since $\llbracket e\rrbracket_{\texttt{env}}$ is a number and
not a list, we defined the function \texttt{range}, which takes as input a natural
number $x$ and returns a list of all numbers from 0 to $x$.

\texttt{flip} simply returns a uniform distribution of \texttt{true} and
\texttt{false}. \\
\\
Our interpretation relies on an environment that is used in order to interpret
recursive definitions. This environment is empty to begin with and the values we
store in it are of distribution type, so a lookup (the interpretation of a variable)
will always yield a distribution, just what we expect the interpretation of an
expression to be. \\
\\
For the supremum in the interpretation of \coqe{sFix}, we rely on the
\texttt{mathcomp} function \texttt{dlim}. This takes the limit of a monotonic
sequence of distributions. Since the result of a recursive definition is either
\texttt{dnull} or the result, the sequence will look something like \texttt{dnull,
  dnull, dnull, $\dots$ result, result, result, $\dots$}; this means that the
supremum of the sequence will be the result of the computation. When a function
diverges, the sequence will consist solely of \texttt{dnull}s  and hence the all-zero
distribution is going to be the supremum. 

\section{Comparisons and future work (READY)}
\label{sec:future}
Our work is mainly based on two different approaches to developing a framework for
proofs of probabilistic algorithms in Coq. On one hand there is \rml\ and the ALEA
library presented by Paulin-Mohring and Audebaud in \cite{rml-paper}; on the other
hand there is \textsc{EasyCrypt}'s \texttt{pwhile} and the Coq implementation of
\texttt{pwhile} in the \texttt{xhl} development.

Another notable development in this subject is the ``Foundational Proof Framework for
Cryptography'', FCF, presented in \cite{fcf}. This work presents a more low-level
functional approach to the same problem, but we did not consider it in our own
development. 

In difference to the works mentioned above, our development focused on comparing and
unifying the different approaches of instead of developing a new framework.\\
\\
The theory we developed in Section \ref{sec:approach} was not fully implemented in
our development, and it would be interesting to continue working on the
implementation of a translation from \texttt{pwhile} to \rml\ and compare their
respective interpretations, as was our suggestion in Section \ref{sec:howto-coq}.

Furthermore, our proofs only show \texttt{pwhile} to be a subset of \rml and do not
show the languages equivalent. Though it intuitively seems that they might be,
proving the equivalence of \texttt{pwhile} and \rml\ might be something upon which to
base future work about developing frameworks for proofs of probabilistic algorithms
in Coq.

Another thing that would be interesting to explore is how FCF fits into the
picture. Intuitively we expect it to have the same expressivity as \rml\ and
\texttt{pwhile}, but it would be interesting to explore the differences in the
interpretations of probabilistic definitions as well as the ease with which algorithms
would be implemented in them.

Lastly it would make sense to explore the possibilities of the different approaches;
which are most usable in practice, and if they could be combined in order to develop
a framework that is more useful than either of the approaches on its own. 

\section{Conclusion (READY)}
\label{sec:conclusion}
% Goal: 1-2 pages
We have in this work looked at two probabilistic languages and their interpretation
in Coq: The functional \rml, and the imperative \texttt{pwhile}.\\
\\
We started by going through the theoretic background of such interpretations, where
we explored how we can interpret probabilistic definitions as probability measures
and how we can represent these measures by use of a monad. We also looked at the
domain theoretic approach to interpreting recursion and iteration without running the
risk of trying to construct a non-terminating algorithm within Coq, since this would
either be disallowed by Coq's termination-checker, or show that we added axioms
that ended up introducing an inconsistency in the logic.

After looking at the interpretations for recursion/iteration, and for probabilistic
definitions, we made sure that it was possible to interpret recursion/iteration in a
probabilistic setting.\\
\\
After having established the theoretic background, we had a look at the syntax and
semantics of \rml\ and \texttt{pwhile}. Seeing their similarity we went ahead proving
that the interpretation of \texttt{pwhile} is a subset of the interpretation of
\rml\ by defining a translation from \texttt{pwhile} to \rml\ and proving that
interpreting the original \texttt{pwhile} program produced a result equivalent to
interpreting the result of translating this \texttt{pwhile} program to \rml.

This proof was carried out by hand. We attempted to prove the same thing in Coq, but
we approached this from the wrong direction and without first gaining a proper
understanding of our goals and the way there, so what was actually implemented is an
interpretation of a language equivalent to \rml.

What we tried to prove the diagram in Figure \ref{fig:triangle} commutative, but we
did not implement a translation from \texttt{pwhile} to \rml. The translations that
are currently implemented can be seen in Figure \ref{fig:triangle-ours}. 
\begin{figure}
  \centering
  \begin{tikzcd}
    \texttt{pwhile} \arrow[dd, dashed] \arrow[rrrrd, "\texttt{xhl}" description] &  &  &  &                     \\
    &  &  &  & \omega \text{-cpos} \\
    \text{\rml} \arrow[rrrru, "\text{this development}" description]          &  &  &  &                    
  \end{tikzcd}
  \caption{The translations of which implementations exist are represented by solid
    arrows labelled by the source they are implemented in, the translation that still
    lacks implementation is marked with a dashed arrow. }
  \label{fig:triangle-ours}
\end{figure}


\paragraph{Ackowledgments}We thank

\newpage
\bibliographystyle{ieeetr}
\bibliography{sources}


\newpage
\begin{appendices}

  \section{Translating \rmlx\ to \srml}
  \label{app:rml-to-srml}
  This appendix presents the function translating \rmlx\ abstract syntax to \srml\
  abstract syntax. The auxiliary function, which is the main workhorse, is defined
  recursively and written in the form of a proof. This is possible because Coq-proofs
  are program terms that can be run. 
\begin{lstlisting}[language=coq]
Fixpoint replace_all_variables_aux_type
         A (x : Rml) (env : seq (nat * Type * Rml))
         (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
         `{x_valid : @@rml_valid_type A (map fst env) fl x} {struct x}
  : verified_srml A fl.
Proof.
  (** Structure **)
  generalize dependent fl.
  generalize dependent env.
  generalize dependent A.
  induction x ; intros.
  (** Var *)
  {
    assert (List.In p (map fst env) \/ List.In p fl) 
    by (inversion x_valid ; subst ; auto).
    destruct p.
    assert (A = T) by (inversion x_valid ; subst ; reflexivity) ; subst.
    apply (@@lookup (n,T) env fl env_valid H).
  }

  (** Const **)
  {
    assert (A0 = A) by (inversion x_valid ; subst ; reflexivity) ; subst.
    exists (sConst a).
    constructor.
  }
      
  (** Let-stm **)
  {
    assert (x1_valid : rml_valid_type p.2 (map fst env) fl x1) 
    by (inversion x_valid ; subst ; assumption).

    pose (x1' := replace_all_variables_aux_type p.2 x1 env fl env_valid x1_valid).
    destruct x1' as [x1'].
    pose (x1'' := @@sRml_to_rml p.2 x1').

    assert (x1''_simple : @@rml_is_simple fl x1'').
    apply sRml_simple.
    assumption.

    assert (x1''_valid : @@rml_valid_type p.2 (map fst env) fl x1'').
    apply sRml_valid.
    assumption.
    
    pose (@@rml_to_sRml_l p.2 x1'' (map fst env) fl).
        
    assert (x2_valid : rml_valid_type A (p :: [seq i.1 | i <- env]) fl x2) 
    by (inversion x_valid ; subst ; assumption).

    assert (env_valid' : valid_env ((p,x1'') :: env) fl) 
    by (constructor ; assumption).
    
    refine (replace_all_variables_aux_type A x2 ((p,x1'') :: env) fl env_valid' x2_valid).
  }
    
  (** If-stm **)
  {
    assert (x1_valid : rml_valid_type bool (map fst env) fl x1) 
    by (inversion x_valid ; subst ; assumption).
    assert (x2_valid : rml_valid_type A (map fst env) fl x2) 
    by (inversion x_valid ; subst ; assumption).
    assert (x3_valid : rml_valid_type A (map fst env) fl x3) 
    by (inversion x_valid ; subst ; assumption).
    
    pose (b' := replace_all_variables_aux_type bool x1 env fl env_valid x1_valid).
    pose (m1' := replace_all_variables_aux_type A x2 env fl env_valid x2_valid).
    pose (m2' := replace_all_variables_aux_type A x3 env fl env_valid x3_valid).

    destruct b' as [b'].
    destruct m1' as [m1'].
    destruct m2' as [m2'].
    
    pose (b'' := sRml_to_rml b').
    pose (m1'' := sRml_to_rml m1').
    pose (m2'' := sRml_to_rml m2').
    
    refine (rml_to_sRml_l (If_stm b'' m1'' m2'') [seq i.1 | i <- env] fl).
    constructor ; eauto using sRml_simple.
    constructor ; eauto using sRml_valid.
  }

  (** App-stm **)
  {
    assert (x1_valid : rml_valid_type (T -> A) (map fst env) fl x1) 
    by (inversion x_valid ; subst ; assumption).
        
    assert (x2_valid : rml_valid_type T (map fst env) fl x2) 
    by (inversion x_valid ; subst ; assumption).
    
    pose (e1' := replace_all_variables_aux_type (T -> A) x1 env fl env_valid x1_valid).
    pose (e2' := replace_all_variables_aux_type T x2 env fl env_valid x2_valid).

    destruct e1' as [e1'].
    destruct e2' as [e2'].
    
    pose (e1'' := sRml_to_rml e1').
    pose (e2'' := sRml_to_rml e2').
    
    refine (rml_to_sRml_l (App_stm T e1'' e2'') [seq i.1 | i <- env] fl).
    constructor ; eauto 2 using sRml_simple.
    constructor ; eauto 2 using sRml_valid.
  }

  (** Let rec **)
  {
    pose (fl_x1 := [:: (n0, T), (n, T -> T0) & fl]).
    
    assert (x1_valid : rml_valid_type A [seq i.1 | i <- env] fl_x1 x1) 
    by (inversion x_valid ; subst ; assumption).
    
    assert (x2_valid : rml_valid_type T [seq i.1 | i <- env] fl x2) 
    by (inversion x_valid ; subst ; assumption).

    
    assert (env_valid_x1 : valid_env env fl_x1) 
    by (repeat apply extend_fl_still_valid ; assumption).
    
    pose (x1' := replace_all_variables_aux_type A x1 env fl_x1 env_valid_x1 x1_valid).
    assert (env_valid_x2 : valid_env env fl) by (repeat apply extend_fl_still_valid ; assumption).
    
    pose (x2' := replace_all_variables_aux_type T x2 env fl env_valid_x2 x2_valid).

    destruct x1' as [x1'].
    destruct x2' as [x2'].
    
    assert (A = T0) by (inversion x_valid ; subst ; reflexivity) ; subst.
    
    exists (sFix T n n0 x1' x2').
    constructor ; assumption.
  }

  (** Random **)
  {
    assert (inner_x_valid : rml_valid_type nat (map fst env) fl x) 
    by (inversion x_valid ; assumption).

    pose (x' := replace_all_variables_aux_type nat x env fl env_valid inner_x_valid).

    assert (type_eq : A = nat) by (inversion x_valid ; reflexivity).

    destruct x' as [x' x'_valid].
    
    exists (sRandom type_eq x').
    constructor ; assumption.
  }

  (** Flip **)
  {
    assert (A = bool) by (inversion x_valid ; reflexivity).
    exists (sFlip H).
    constructor.
  }
Defined.

Definition replace_all_variables_type A (x : Rml)
           `{x_valid : rml_valid_type A nil nil x} :=
  @@replace_all_variables_aux_type A x nil nil (env_nil nil) x_valid.

\end{lstlisting}
  \newpage
  \section{\rmlx\ typing rules}
  \label{appendix:rmltypes}
\begin{lstlisting}[language=coq]
Inductive rml_valid_type : Type -> seq (nat * Type) -> seq (nat * Type) -> Rml -> Prop :=
| valid_var : forall vl fl p,
    List.In p vl ->
    rml_valid_type p.2 vl fl (Var p false)

| valid_fun_var : forall vl fl p,
    List.In p fl ->
    rml_valid_type p.2 vl fl (Var p true)
                   
| valid_const : forall (A : Type) vl fl (c : A),
    rml_valid_type A vl fl (@@Const A c)
                   
| valid_let : forall A vl fl p a b,
    @@rml_valid_type p.2 vl fl a ->
    @@rml_valid_type A (p :: vl) fl b ->
    rml_valid_type A vl fl (Let_stm p a b)
                   
| valid_if : forall A vl fl b m1 m2,
    rml_valid_type bool vl fl b ->
    rml_valid_type A vl fl m1 ->
    rml_valid_type A vl fl m2 ->
    rml_valid_type A vl fl (If_stm b m1 m2)
                   
| valid_app : forall A vl fl (B : Type) e1 e2,
    rml_valid_type (B -> A) vl fl e1 ->
    rml_valid_type B vl fl e2 ->
    rml_valid_type A vl fl (App_stm B e1 e2)

| valid_let_rec : forall A vl fl B nf nx e1 e2,
    @@rml_valid_type A vl ((nx,B) :: (nf,B -> A) :: fl) e1 ->
    @@rml_valid_type B vl fl e2 ->
    rml_valid_type A vl fl (Let_rec B A nf nx e1 e2)

| valid_random : forall vl fl e,
    rml_valid_type nat vl fl e ->
    rml_valid_type nat vl fl (Random e)

| valid_flip : forall vl fl,
    rml_valid_type bool vl fl Flip.
\end{lstlisting}
  \newpage

  \section{Example - Error: Stack Overflow.}
\begin{lstlisting}[language=coq]
Fixpoint replace_all_variables_aux_type
         A (x : Rml) (env : seq (nat * Type * Rml))
         (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
         `{x_valid : @rml_valid_type A (map fst env) fl x} : @sRml A
                                                                            
with replace_all_variables_aux_type_const
       A0 A a (env : seq (nat * Type * Rml))
       (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
       `{x_valid : @rml_valid_type A0 (map fst env) fl (Const A a)} : @sRml A0
with replace_all_variables_aux_type_let
       A p x1 x2 (env : seq (nat * Type * Rml))
       (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
       `{x_valid : @rml_valid_type A (map fst env) fl (Let_stm p x1 x2)} : @sRml A
with replace_all_variables_aux_type_fun
       A T p x (env : seq (nat * Type * Rml))
       (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
       `{x_valid : @rml_valid_type A (map fst env) fl (Fun_stm T p x)} : @sRml A
with replace_all_variables_aux_type_if
       A x1 x2 x3 (env : seq (nat * Type * Rml))
       (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
       `{x_valid : @rml_valid_type A (map fst env) fl (If_stm x1 x2 x3)} : @sRml A
with replace_all_variables_aux_type_app
       A T x1 x2 (env : seq (nat * Type * Rml))
       (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
       `{x_valid : @rml_valid_type A (map fst env) fl (App_stm T x1 x2)} : @sRml A
with replace_all_variables_aux_type_let_rec A T T0 n n0 x1 x2 (env : seq (nat * Type * Rml))
     (fl : seq (nat * Type)) `{env_valid : valid_env env fl}
     `{x_valid : @rml_valid_type A (map fst env) fl (Let_rec T T0 n n0 x1 x2)} : @sRml A.
Proof.
  (** Structure **)
  {
    induction x ; intros ; refine (sVar (0,A)).
  }
  
  all: refine (sVar (0,A)).  
Defined.
\end{lstlisting}


\end{appendices}

\end{document}
